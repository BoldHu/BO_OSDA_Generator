{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from datasets.data_loader import *\n",
    "from models.cvae import *\n",
    "from models.loss import InfoNCELoss\n",
    "from models.trfm import *\n",
    "from utils.utils import *\n",
    "from utils.plot_figures import *\n",
    "from utils.metrics import *\n",
    "from utils.build_vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "EOS = 2\n",
    "SOS = 3\n",
    "MASK = 4\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cvae(model, condition, tgt_input, vocab, device='cuda', max_len=MAX_LEN, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates SMILES strings from a trained CVAE model, given an already-merged synthesis condition.\n",
    "\n",
    "    Args:\n",
    "        model:       The trained ConditionalVAE model (must implement model.generate).\n",
    "        condition:   (B, cond_dim) - the already-merged condition vector (e.g., torch.cat([zeo, syn], dim=-1)).\n",
    "        tgt_input:   (B, seq_len) - the input SMILES sequence (e.g., the '<sos>' token).\n",
    "        vocab:       The vocabulary object (must implement vocab.idx2char).\n",
    "        device:      'cuda' or 'cpu'.\n",
    "        max_len:     Maximum length of generated SMILES.\n",
    "\n",
    "    Returns:\n",
    "        smiles_list: A list of generated SMILES strings (length = batch size).\n",
    "                     Each string excludes '<sos>', ignores '<pad>', and is cut after '<eos>'.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    smiles_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Move condition to device\n",
    "        condition = condition.to(device)\n",
    "        \n",
    "        # Generate SMILES strings\n",
    "        # Assuming the model has a generate function that takes condition as input\n",
    "        # generated = model.generate(condition, max_len=max_len, device=device, teacher_force_inputs=tgt_input)  # shape: (B, seq_len)\n",
    "        logits, z_mean, z_log = model(\n",
    "            x_smi=tgt_input,         # SMILES input\n",
    "            x_cond=condition,        # condition\n",
    "            teacher_force_inputs=tgt_input  # Use teacher forcing during inference\n",
    "        )\n",
    "\n",
    "        # sample from the logits using multinomial\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        generated = torch.multinomial(probs.view(-1, probs.size(-1)), num_samples=1).view(probs.size(0), probs.size(1))\n",
    "        \n",
    "        \n",
    "        for i in range(generated.size(0)):\n",
    "            # Convert the generated token IDs to SMILES string\n",
    "            smi = []\n",
    "            for idx in generated[i]:\n",
    "                # Convert index to character, skipping padding or other invalid tokens\n",
    "                char = vocab.itos[idx.item()]\n",
    "                if char == '<eos>':  # End of the SMILES string\n",
    "                    break\n",
    "                if char not in ('<sos>', '<pad>'):  # Remove unwanted characters\n",
    "                    smi.append(char)\n",
    "            smiles_list.append(''.join(smi))\n",
    "\n",
    "    return smiles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "AFI_smiles = read_strings('./data_AFI/AFI_smiles.csv', idx=False)\n",
    "AFI_zeo = read_vec('./data_AFI/AFI_zeo.csv', idx=False)\n",
    "AFI_syn = read_vec('./data_AFI/AFI_syn.csv', idx=False)\n",
    "CHA_smiles = read_strings('./data_CHA/CHA_smiles.csv', idx=False)\n",
    "CHA_zeo = read_vec('./data_CHA/CHA_zeo.csv', idx=False)\n",
    "CHA_syn = read_vec('./data_CHA/CHA_syn.csv', idx=False)\n",
    "\n",
    "vocab = WordVocab.load_vocab('./model_hub/vocab.pkl')\n",
    "print('the vocab size is :', len(vocab))\n",
    "charlen = len(vocab)\n",
    "print('the total num of charset is :', charlen)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "batch_size = 64\n",
    "\n",
    "manual_seed = 42\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create the dataset and dataloader\n",
    "AFI_dataset = Seq2seqDataset(AFI_zeo, AFI_syn, AFI_smiles, vocab)\n",
    "CHA_dataset = Seq2seqDataset(CHA_zeo, CHA_syn, CHA_smiles, vocab)\n",
    "AFI_dataloader = DataLoader(AFI_dataset, batch_size=batch_size, shuffle=True)\n",
    "CHA_dataloader = DataLoader(CHA_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original model and contrastive model\n",
    "# Suppose we have:\n",
    "params = {\n",
    "    'NCHARS': charlen,\n",
    "    'MAX_LEN': MAX_LEN,\n",
    "    'COND_DIM': 24,\n",
    "    'hidden_dim': 256,\n",
    "    'conv_depth': 3,\n",
    "    'conv_dim_depth': 64,\n",
    "    'conv_dim_width': 3,\n",
    "    'conv_d_growth_factor': 2,\n",
    "    'conv_w_growth_factor': 1,\n",
    "    'middle_layer': 2,\n",
    "    'activation': 'tanh',\n",
    "    'batchnorm_conv': True,\n",
    "    'batchnorm_mid': True,\n",
    "    'dropout_rate_mid': 0.2,\n",
    "    'gru_depth': 2,\n",
    "    'recurrent_dim': 256,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "encoder = ConditionalEncoder(\n",
    "    input_channels=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    conv_depth=params['conv_depth'],\n",
    "    conv_dim_depth=params['conv_dim_depth'],\n",
    "    conv_dim_width=params['conv_dim_width'],\n",
    "    conv_d_growth_factor=params['conv_d_growth_factor'],\n",
    "    conv_w_growth_factor=params['conv_w_growth_factor'],\n",
    "    middle_layer=params['middle_layer'],\n",
    "    activation=params['activation'],\n",
    "    batchnorm_conv=params['batchnorm_conv'],\n",
    "    batchnorm_mid=params['batchnorm_mid'],\n",
    "    dropout_rate_mid=params['dropout_rate_mid']\n",
    ").to(device)\n",
    "\n",
    "decoder = ConditionalDecoder(\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    n_chars=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    gru_depth=params['gru_depth'],\n",
    "    recurrent_dim=params['recurrent_dim'],\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "model_origin = ConditionalVAE(encoder, decoder)\n",
    "model_origin.load_state_dict(torch.load('./checkpoints/best_cvae_model.pth'))\n",
    "model_origin = model_origin.to(device)\n",
    "model_origin.eval()\n",
    "\n",
    "model_cl = ConditionalVAE(encoder, decoder)\n",
    "model_cl.load_state_dict(torch.load('./checkpoints/best_cvae_contrastive_model.pth'))\n",
    "model_cl = model_cl.to(device)\n",
    "model_cl.eval()\n",
    "\n",
    "total = sum(p.numel() for p in model_origin.parameters())\n",
    "print('total parameters: %0.2fM' % (total / 1e6))  # print the total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the AFI smiles with the original model\n",
    "generated_smile_origin = []\n",
    "target_smile_origin = []\n",
    "for i, (zeo, syn, tgt) in enumerate(tqdm(AFI_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "    tgt_input = tgt[:, :-1].contiguous()\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "    generated_smiles = generate_cvae(model=model_origin, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile_origin.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile_origin.extend(tgt_smiles)\n",
    "    \n",
    "# calculate the metrics\n",
    "AFI_validity_rate_origin = validity_rate(generated_smile_origin)\n",
    "AFI_uniqueness_rate_origin = uniqueness_rate(generated_smile_origin)\n",
    "AFI_novelty_rate_origin = novelty_rate(generated_smile_origin, target_smile_origin)\n",
    "AFI_reconstructability_rate_origin = reconstructability_rate(generated_smile_origin, target_smile_origin)\n",
    "AFI_IntDiv_origin = IntDiv(generated_smile_origin)\n",
    "AFI_FCD_score_origin = FCD_score(target_smile_origin, generated_smile_origin)\n",
    "# print the metrics\n",
    "print('AFI_validity_rate_origin: ', AFI_validity_rate_origin)\n",
    "print('AFI_uniqueness_rate_origin: ', AFI_uniqueness_rate_origin)\n",
    "print('AFI_novelty_rate_origin: ', AFI_novelty_rate_origin)\n",
    "print('AFI_reconstructability_rate_origin: ', AFI_reconstructability_rate_origin)\n",
    "print('AFI_IntDiv_origin: ', AFI_IntDiv_origin)\n",
    "print('AFI_FCD_score_origin: ', AFI_FCD_score_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the AFI smiles with the contrastive learning model\n",
    "generated_smile_cl = []\n",
    "target_smile_cl = []\n",
    "for i, (zeo, syn, tgt) in enumerate(tqdm(AFI_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "    tgt_input = tgt[:, :-1].contiguous()\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "    generated_smiles = generate_cvae(model=model_cl, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile_cl.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile_cl.extend(tgt_smiles)\n",
    "\n",
    "# calculate the metrics\n",
    "AFI_validity_rate_cl = validity_rate(generated_smile_cl)\n",
    "AFI_uniqueness_rate_cl = uniqueness_rate(generated_smile_cl)\n",
    "AFI_novelty_rate_cl = novelty_rate(generated_smile_cl, target_smile_cl)\n",
    "AFI_reconstructability_rate_cl = reconstructability_rate(generated_smile_cl, target_smile_cl)\n",
    "AFI_IntDiv_cl = IntDiv(generated_smile_cl)\n",
    "AFI_FCD_score_cl = FCD_score(target_smile_cl, generated_smile_cl)\n",
    "# print the metrics\n",
    "print('AFI_validity_rate_cl: ', AFI_validity_rate_cl)\n",
    "print('AFI_uniqueness_rate_cl: ', AFI_uniqueness_rate_cl)\n",
    "print('AFI_novelty_rate_cl: ', AFI_novelty_rate_cl)\n",
    "print('AFI_reconstructability_rate_cl: ', AFI_reconstructability_rate_cl)\n",
    "print('AFI_IntDiv_cl: ', AFI_IntDiv_cl)\n",
    "print('AFI_FCD_score_cl: ', AFI_FCD_score_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the metrics to the folder data_AFI\n",
    "with open('./data_AFI/AFI_generated_cvae_metrics.txt', 'w') as f:\n",
    "    # write the mertics\n",
    "    f.write(f'AFI_validity_rate_origin: {AFI_validity_rate_origin}, AFI_validity_rate_cl: {AFI_validity_rate_cl}\\n')\n",
    "    f.write(f'AFI_uniqueness_rate_origin: {AFI_uniqueness_rate_origin}, AFI_uniqueness_rate_cl: {AFI_uniqueness_rate_cl}\\n')\n",
    "    f.write(f'AFI_novelty_rate_origin: {AFI_novelty_rate_origin}, AFI_novelty_rate_cl: {AFI_novelty_rate_cl}\\n')\n",
    "    f.write(f'AFI_reconstructability_rate_origin: {AFI_reconstructability_rate_origin}, AFI_reconstructability_rate_cl: {AFI_reconstructability_rate_cl}\\n')\n",
    "    f.write(f'AFI_IntDiv_origin: {AFI_IntDiv_origin}, AFI_IntDiv_cl: {AFI_IntDiv_cl}\\n')\n",
    "    f.write(f'AFI_FCD_score_origin: {AFI_FCD_score_origin}, AFI_FCD_score_cl: {AFI_FCD_score_cl}\\n')\n",
    "\n",
    "# write the generated smiles (origin and cl) and target smiles to the folder data_AFI\n",
    "with open('./data_AFI/AFI_generated_cvae_smiles_origin.txt', 'w') as f:\n",
    "    for smiles in range(len(generated_smile_origin)):\n",
    "        f.write(f'origin: {generated_smile_origin[smiles]}, cl: {generated_smile_cl[smiles]}, target: {target_smile_origin[smiles]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the CHA smiles with the original model\n",
    "generated_smile_origin = []\n",
    "target_smile_origin = []\n",
    "for i, (zeo, syn, tgt) in enumerate(tqdm(CHA_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "    generated_smiles = generate_cvae(model=model_origin, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile_origin.extend(generated_smiles)\n",
    "    generated_smile_origin.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile_origin.extend(tgt_smiles)\n",
    "\n",
    "# calculate the metrics\n",
    "CHA_validity_rate_origin = validity_rate(generated_smile_origin)\n",
    "CHA_uniqueness_rate_origin = uniqueness_rate(generated_smile_origin)\n",
    "CHA_novelty_rate_origin = novelty_rate(generated_smile_origin, target_smile_origin)\n",
    "CHA_reconstructability_rate_origin = reconstructability_rate(generated_smile_origin, target_smile_origin)\n",
    "CHA_IntDiv_origin = IntDiv(generated_smile_origin)\n",
    "CHA_FCD_score_origin = FCD_score(target_smile_origin, generated_smile_origin)\n",
    "# print the metrics\n",
    "print('CHA_validity_rate_origin: ', CHA_validity_rate_origin)\n",
    "print('CHA_uniqueness_rate_origin: ', CHA_uniqueness_rate_origin)\n",
    "print('CHA_novelty_rate_origin: ', CHA_novelty_rate_origin)\n",
    "print('CHA_reconstructability_rate_origin: ', CHA_reconstructability_rate_origin)\n",
    "print('CHA_IntDiv_origin: ', CHA_IntDiv_origin)\n",
    "print('CHA_FCD_score_origin: ', CHA_FCD_score_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the CHA smiles with the contrastive learning model\n",
    "generated_smile_cl = []\n",
    "target_smile_cl = []\n",
    "for i, (zeo, syn, tgt) in enumerate(tqdm(CHA_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "    tgt_input = tgt[:, :-1].contiguous()\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "    generated_smiles = generate_cvae(model=model_cl, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile_cl.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile_cl.extend(tgt_smiles)\n",
    "\n",
    "# calculate the metrics\n",
    "CHA_validity_rate_cl = validity_rate(generated_smile_cl)\n",
    "CHA_uniqueness_rate_cl = uniqueness_rate(generated_smile_cl)\n",
    "CHA_novelty_rate_cl = novelty_rate(generated_smile_cl, target_smile_cl)\n",
    "CHA_reconstructability_rate_cl = reconstructability_rate(generated_smile_cl, target_smile_cl)\n",
    "CHA_IntDiv_cl = IntDiv(generated_smile_cl)\n",
    "CHA_FCD_score_cl = FCD_score(target_smile_cl, generated_smile_cl)\n",
    "# print the metrics\n",
    "print('CHA_validity_rate_cl: ', CHA_validity_rate_cl)\n",
    "print('CHA_uniqueness_rate_cl: ', CHA_uniqueness_rate_cl)\n",
    "print('CHA_novelty_rate_cl: ', CHA_novelty_rate_cl)\n",
    "print('CHA_reconstructability_rate_cl: ', CHA_reconstructability_rate_cl)\n",
    "print('CHA_IntDiv_cl: ', CHA_IntDiv_cl)\n",
    "print('CHA_FCD_score_cl: ', CHA_FCD_score_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the metrics to the folder data_CHA\n",
    "with open('./data_CHA/CHA_generated_cvae_metrics.txt', 'w') as f:\n",
    "    # write the mertics\n",
    "    f.write(f'CHA_validity_rate_origin: {CHA_validity_rate_origin}, CHA_validity_rate_cl: {CHA_validity_rate_cl}\\n')\n",
    "    f.write(f'CHA_uniqueness_rate_origin: {CHA_uniqueness_rate_origin}, CHA_uniqueness_rate_cl: {CHA_uniqueness_rate_cl}\\n')\n",
    "    f.write(f'CHA_novelty_rate_origin: {CHA_novelty_rate_origin}, CHA_novelty_rate_cl: {CHA_novelty_rate_cl}\\n')\n",
    "    f.write(f'CHA_reconstructability_rate_origin: {CHA_reconstructability_rate_origin}, CHA_reconstructability_rate_cl: {CHA_reconstructability_rate_cl}\\n')\n",
    "    f.write(f'CHA_IntDiv_origin: {CHA_IntDiv_origin}, CHA_IntDiv_cl: {CHA_IntDiv_cl}\\n')\n",
    "    f.write(f'CHA_FCD_score_origin: {CHA_FCD_score_origin}, CHA_FCD_score_cl: {CHA_FCD_score_cl}\\n')\n",
    "# write the generated smiles (origin and cl) and target smiles to the folder data_CHA\n",
    "with open('./data_CHA/CHA_generated_cvae_smiles_origin.txt', 'w') as f:\n",
    "    for smiles in range(len(generated_smile_origin)):\n",
    "        f.write(f'origin: {generated_smile_origin[smiles]}, cl: {generated_smile_cl[smiles]}, target: {target_smile_origin[smiles]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
