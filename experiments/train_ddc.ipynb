{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DDC Model for Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hudongcheng/Desktop/bo_osda_generator\n"
     ]
    }
   ],
   "source": [
    "# change working path to the current file\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from models.ddc import SMILESGenerator\n",
    "from utils.utils import *\n",
    "from datasets.data_loader import *\n",
    "from utils.plot_figures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "log_dir = './logs/'\n",
    "save_best_weight_path = './checkpoints/'\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the charset(inculde begin end and pad char) achieved from dataset : ?P25$]FO-S.Hc=71(ln63NC4[+)^@\n",
      "the total num of charset is : 29\n"
     ]
    }
   ],
   "source": [
    "# read the data and convert to the format we need\n",
    "train_smiles = read_strings('./data/train_smiles.csv', idx=False)\n",
    "train_zeo = read_vec('./data/train_zeo.csv', idx=False)\n",
    "train_syn = read_vec('./data/train_syn.csv', idx=False)\n",
    "train_codes = read_strings('./data/train_codes.csv', idx=False)\n",
    "test_smiles = read_strings('./data/test_smiles.csv', idx=False)\n",
    "test_zeo = read_vec('./data/test_zeo.csv', idx=False)\n",
    "test_syn = read_vec('./data/test_syn.csv', idx=False)\n",
    "test_codes = read_strings('./data/test_codes.csv', idx=False)\n",
    "\n",
    "charset = '?P25$]FO-S.Hc=71(ln63NC4[+)^@'\n",
    "charlen = len(charset)\n",
    "print('the charset(inculde begin end and pad char) achieved from dataset :', charset)\n",
    "print('the total num of charset is :', charlen)\n",
    "# create the char to index and index to char dictionary\n",
    "char_to_index = dict((c, i) for i, c in enumerate(charset))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(charset))\n",
    "char_list = [k for k, v in char_to_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 512\n",
    "epoch = 10\n",
    "seqlen = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 1.39M\n"
     ]
    }
   ],
   "source": [
    "src_smiles, tgt_smiles = smiles_padding(train_smiles)\n",
    "tgt_seq = smiles_to_sequence(tgt_smiles, char_to_index)\n",
    "tgt_seq = torch.cat([torch.unsqueeze(seq, 0) for seq in tgt_seq]).long()\n",
    "src_smiles_test, tgt_smiles_test = smiles_padding(test_smiles)\n",
    "tgt_seq_test = smiles_to_sequence(tgt_smiles_test, char_to_index)\n",
    "tgt_seq_test = torch.cat([torch.unsqueeze(seq, 0) for seq in tgt_seq_test]).long()\n",
    "# create the dataset and dataloader\n",
    "train_dataset = SeqDataset(train_zeo, train_syn, tgt_seq)\n",
    "test_dataset = SeqDataset(test_zeo, test_syn, tgt_seq_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# create the model\n",
    "model = SMILESGenerator(condition_dim=24, lstm_dim=256, dec_layers=3, charset_size=charlen).to(device)\n",
    "# loss\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=char_to_index['?'])\n",
    "optim = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print('total parameters: %0.2fM' % (total / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(model, dataloader, loss_func, optim, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    for i, (zeo, syn, tgt) in enumerate(tqdm(dataloader)):\n",
    "        zeo = zeo.to(device)\n",
    "        syn = syn.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        # teacher forcing\n",
    "        condition = torch.cat([zeo, syn], dim=-1)\n",
    "        tgt_input = tgt[:, :-1].contiguous()\n",
    "        tgt_output = tgt[:, 1:].contiguous()\n",
    "        # convert the tgt_input to one-hot\n",
    "        tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        output = model(condition, tgt_input)\n",
    "        \n",
    "        # reshape the output to calculate the loss\n",
    "        output = output.view(-1, output.size(-1))\n",
    "        tgt_output = tgt_output.view(-1)\n",
    "        loss = loss_func(output, tgt_output)\n",
    "        \n",
    "        # backward and update\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # calculate the accuracy and loss\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=-1)\n",
    "        num_correct = (pred == tgt_output) & (tgt_output != char_to_index['?'])\n",
    "        num_words = (tgt_output != char_to_index['?']).sum().item()\n",
    "        total_acc += num_correct.sum().item()\n",
    "        total_num += num_words\n",
    "    return total_loss / len(dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "def test(model, dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (zeo, syn, tgt) in enumerate(tqdm(dataloader)):\n",
    "            zeo = zeo.to(device)\n",
    "            syn = syn.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            condition = torch.cat([zeo, syn], dim=-1)\n",
    "            tgt_input = tgt[:, :-1].contiguous()\n",
    "            tgt_output = tgt[:, 1:].contiguous()\n",
    "            tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "            output = model(condition, tgt_input)\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            tgt_output = tgt_output.view(-1)\n",
    "            loss = loss_func(output, tgt_output)\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=-1)\n",
    "            num_correct = (pred == tgt_output) & (tgt_output != char_to_index['?'])\n",
    "            num_words = (tgt_output != char_to_index['?']).sum().item()\n",
    "            total_acc += num_correct.sum().item()\n",
    "            total_num += num_words\n",
    "    return total_loss / len(dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:10<00:00, 27.91it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 91.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 1.9554, train acc 0.4202, test loss 1.5225, test acc 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.83it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 91.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss 1.3777, train acc 0.5493, test loss 1.2971, test acc 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.73it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 94.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss 1.2037, train acc 0.5919, test loss 1.1425, test acc 0.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.69it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 91.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss 1.0705, train acc 0.6298, test loss 1.0593, test acc 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.72it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 91.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss 0.9720, train acc 0.6579, test loss 0.9852, test acc 0.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.76it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 94.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss 0.9019, train acc 0.6782, test loss 0.9113, test acc 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.61it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 94.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss 0.8469, train acc 0.6941, test loss 0.8546, test acc 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.62it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 94.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss 0.8018, train acc 0.7079, test loss 0.8537, test acc 0.6902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.44it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 93.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss 0.7666, train acc 0.7186, test loss 0.7876, test acc 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:09<00:00, 28.55it/s]\n",
      "100%|██████████| 68/68 [00:00<00:00, 91.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss 0.7347, train acc 0.7278, test loss 0.7681, test acc 0.7170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc = train(model, train_dataloader, loss_func, optim, device)\n",
    "    test_loss, test_acc = test(model, test_dataloader, loss_func, device)\n",
    "    print('epoch %d, train loss %.4f, train acc %.4f, test loss %.4f, test acc %.4f' % (i, train_loss, train_acc, test_loss, test_acc))\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_acc)\n",
    "    if i == 0:\n",
    "        best_acc = test_acc\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), os.path.join(save_best_weight_path, 'best_ddc_model.pth'))\n",
    "    torch.save(model.state_dict(), os.path.join(save_best_weight_path, 'last_ddc_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ddc(model, start_sequence, condition, seqlen, \n",
    "                 char_to_index, index_to_char, device, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Auto-regressively generate SMILES sequence\n",
    "\n",
    "    Args: \n",
    "        model (nn.Module): The SMILESGenerator (or similar) model.\n",
    "        start_sequence (torch.Tensor): Already-converted indices for the initial tokens.\n",
    "            Can be of shape (batch_size, start_len) or (start_len,) if batch_size = 1.\n",
    "        condition (torch.Tensor): The condition tensor of shape (batch_size, condition_dim).\n",
    "        seqlen (int): The total desired length of the SMILES (including start tokens).\n",
    "        char_to_index (dict): Mapping from character to integer index.\n",
    "        index_to_char (dict): Mapping from integer index back to character.\n",
    "        device (torch.device): The device on which to run the generation.\n",
    "        temperature (float): Temperature for sampling.\n",
    "\n",
    "    Returns:\n",
    "        If batch_size == 1, returns a single SMILES string.\n",
    "        Otherwise, returns a list of SMILES strings, one for each item in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # 1) If start_sequence is 1D, we assume batch_size = 1. Make it (1, start_len).\n",
    "    if start_sequence.dim() == 1:\n",
    "        start_sequence = start_sequence.unsqueeze(0)  # shape: (1, start_len)\n",
    "    start_sequence = start_sequence.to(device)\n",
    "\n",
    "    # 2) Determine batch_size and starting sequence length\n",
    "    batch_size, start_len = start_sequence.size()\n",
    "\n",
    "    # 3) Create a (batch_size, seqlen) tensor for token indices \n",
    "    #    Initialize all to 0, then copy in the start_sequence for each batch example\n",
    "    generated_seq = torch.zeros(batch_size, seqlen, dtype=torch.long, device=device)\n",
    "    generated_seq[:, :start_len] = start_sequence\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # We will iteratively fill positions from [start_len ... seqlen-1]\n",
    "        for t in range(start_len, seqlen):\n",
    "\n",
    "            # 4) One-hot encode the tokens up to current time step t\n",
    "            #    shape -> (batch_size, t, charset_size)\n",
    "            dec_input = F.one_hot(generated_seq[:, :t], \n",
    "                                  num_classes=len(char_to_index)).float()\n",
    "\n",
    "            # 5) Get the model output\n",
    "            #    output.shape = (batch_size, t, charset_size)\n",
    "            output = model(condition, dec_input)\n",
    "\n",
    "            # 6) Get the logits for the *last* time step (index = t-1)\n",
    "            #    output[:, -1, :].shape = (batch_size, charset_size)\n",
    "            last_step_logits = output[:, -1, :]\n",
    "\n",
    "            # 7) Sample from these logits using temperature\n",
    "            probs = F.softmax(last_step_logits / temperature, dim=-1)\n",
    "            sampled_idx = torch.multinomial(probs, 1).squeeze(1)  # shape: (batch_size,)\n",
    "\n",
    "            # 8) Update generated_seq\n",
    "            #    But we can also stop if the previous token was '$' (end-of-sequence)\n",
    "            end_token_idx = char_to_index.get('$', None)\n",
    "            for b in range(batch_size):\n",
    "                if end_token_idx is not None and generated_seq[b, t-1] == end_token_idx:\n",
    "                    # If the previous character was already end-of-sequence,\n",
    "                    # we do not overwrite. We just leave future steps as 0.\n",
    "                    continue\n",
    "                generated_seq[b, t] = sampled_idx[b]\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    # Convert token indices back to SMILES strings,\n",
    "    # stopping at the first '$' if encountered.\n",
    "    # ----------------------------------------------------------------------\n",
    "    smiles_outputs = []\n",
    "    for b in range(batch_size):\n",
    "        tokens = []\n",
    "        for idx in generated_seq[b]:\n",
    "            ch = index_to_char[idx.item()]\n",
    "            if ch == '$':\n",
    "                break\n",
    "            elif ch == '^':\n",
    "                continue\n",
    "            tokens.append(ch)\n",
    "        smiles_outputs.append(\"\".join(tokens))\n",
    "    \n",
    "    # Return single string if batch_size == 1, otherwise a list\n",
    "    if batch_size == 1:\n",
    "        return smiles_outputs[0]\n",
    "    else:\n",
    "        return smiles_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target smiles:\n",
      "[['n1(C)c(C)[n+](cc1)Cc1ccccc1C[n+]1ccn(C)c1C']\n",
      " ['Cn1cc[n+](Cc2ccccc2C[n+]2ccn(C)c2C)c1C']\n",
      " ['Cc1n(C)cc[n+]1Cc1c(cccc1)C[n+]1ccn(c1C)C']\n",
      " ['c1ccc(c(c1)C[n+]1c(C)n(C)cc1)C[n+]1ccn(c1C)C']\n",
      " ['[n+]1(c(n(C)cc1)C)Cc1c(C[n+]2ccn(c2C)C)cccc1']\n",
      " ['Cc1n(C)cc[n+]1Cc1ccccc1C[n+]1c(n(cc1)C)C']\n",
      " ['Cn1c(C)[n+](cc1)Cc1ccccc1C[n+]1ccn(c1C)C']\n",
      " ['c1c[n+](Cc2ccccc2C[n+]2c(C)n(cc2)C)c(C)n1C']\n",
      " ['n1(cc[n+](c1C)Cc1ccccc1C[n+]1ccn(C)c1C)C']\n",
      " ['[n+]1(Cc2c(C[n+]3c(n(cc3)C)C)cccc2)c(C)n(C)cc1']]\n",
      "generated smiles:\n",
      "['^c1cC(c)c(C1nccc[[++12cc((())C)ncC2)ccCccc', '^ccc(ccCPnnCn[[+]1cCnncc))', '^cccCc(ccn)C)-11[n+](cc(c))))', '^C(1CC[C+](()1CCC)CC[)+]1(C)(CCCC1)C', '^c1[(+](C))CCc3ccCccc3C[n+]3ccC(C(c)c)4)c2ncccC)', '^c1cccCc(c[)+11CnCccCcnnc', '^cN2ccc(cc1)C[N+]12CCCCCC122C(C)CCC1CCC', '^c((2(((C)))c)ccn1CCNCCO1CONCOOC1OCC(OC2NCCOCCOOCOOCOOCOOC(C)CCO2COOCOOC1CCOC', '^C(C[[+]]]2(C)CCC3C((N2C(C(C)C2)C3CCCC3)C))1', '^c1cCcncccC)n[[+]11nn(cc11CCCCCC)C']\n"
     ]
    }
   ],
   "source": [
    "# test the generate function\n",
    "# check the first 10 samples\n",
    "train_zeo = train_zeo[:10].astype(np.float32)\n",
    "train_syn = train_syn[:10].astype(np.float32)\n",
    "zeo = torch.tensor(train_zeo, dtype=torch.float32).to(device)\n",
    "syn = torch.tensor(train_syn, dtype=torch.float32).to(device)\n",
    "target_smi = train_smiles[:10]\n",
    "start_sequence = torch.full((10, 1), char_to_index['^'], dtype=torch.long)\n",
    "start_sequence = start_sequence.to(device)\n",
    "condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "generated_smiles = generate_ddc(model, start_sequence, condition_synthesis, seqlen, char_to_index, index_to_char, device, 0.5)\n",
    "print('target smiles:')\n",
    "print(target_smi)\n",
    "print('generated smiles:')\n",
    "print(generated_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss and acc\n",
    "plot_loss(train_loss_history, test_loss_history, 'ddc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
