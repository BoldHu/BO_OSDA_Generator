{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CVAE Model for Conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working path to the current file\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from models.cvae import *\n",
    "from utils.utils import *\n",
    "from datasets.data_loader import *\n",
    "from utils.plot_figures import *\n",
    "from utils.metrics import *\n",
    "from utils.build_vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "log_dir = './logs/'\n",
    "save_best_weight_path = './checkpoints/'\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "EOS = 2\n",
    "SOS = 3\n",
    "MASK = 4\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data and convert to the format we need\n",
    "train_smiles = read_strings('./data/train_smiles.csv', idx=False)\n",
    "train_zeo = read_vec('./data/train_zeo.csv', idx=False)\n",
    "train_syn = read_vec('./data/train_syn.csv', idx=False)\n",
    "train_codes = read_strings('./data/train_codes.csv', idx=False)\n",
    "test_smiles = read_strings('./data/test_smiles.csv', idx=False)\n",
    "test_zeo = read_vec('./data/test_zeo.csv', idx=False)\n",
    "test_syn = read_vec('./data/test_syn.csv', idx=False)\n",
    "test_codes = read_strings('./data/test_codes.csv', idx=False)\n",
    "\n",
    "vocab = WordVocab.load_vocab('./model_hub/vocab.pkl')\n",
    "print('the vocab size is :', len(vocab))\n",
    "\n",
    "charlen = len(vocab)\n",
    "print('the total num of charset is :', charlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 512\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset and dataloader\n",
    "train_dataset = Seq2seqDataset(train_zeo, train_syn, train_smiles, vocab)\n",
    "test_dataset = Seq2seqDataset(test_zeo, test_syn, test_smiles, vocab)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have:\n",
    "params = {\n",
    "    'NCHARS': charlen,\n",
    "    'MAX_LEN': MAX_LEN,\n",
    "    'COND_DIM': 24,\n",
    "    'hidden_dim': 256,\n",
    "    'conv_depth': 3,\n",
    "    'conv_dim_depth': 64,\n",
    "    'conv_dim_width': 3,\n",
    "    'conv_d_growth_factor': 2,\n",
    "    'conv_w_growth_factor': 1,\n",
    "    'middle_layer': 2,\n",
    "    'activation': 'tanh',\n",
    "    'batchnorm_conv': True,\n",
    "    'batchnorm_mid': True,\n",
    "    'dropout_rate_mid': 0.2,\n",
    "    'gru_depth': 2,\n",
    "    'recurrent_dim': 256,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "encoder = ConditionalEncoder(\n",
    "    input_channels=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    conv_depth=params['conv_depth'],\n",
    "    conv_dim_depth=params['conv_dim_depth'],\n",
    "    conv_dim_width=params['conv_dim_width'],\n",
    "    conv_d_growth_factor=params['conv_d_growth_factor'],\n",
    "    conv_w_growth_factor=params['conv_w_growth_factor'],\n",
    "    middle_layer=params['middle_layer'],\n",
    "    activation=params['activation'],\n",
    "    batchnorm_conv=params['batchnorm_conv'],\n",
    "    batchnorm_mid=params['batchnorm_mid'],\n",
    "    dropout_rate_mid=params['dropout_rate_mid']\n",
    ").to(device)\n",
    "\n",
    "decoder = ConditionalDecoder(\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    n_chars=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    gru_depth=params['gru_depth'],\n",
    "    recurrent_dim=params['recurrent_dim'],\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "model = ConditionalVAE(encoder, decoder).to(device)\n",
    "\n",
    "# loss\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print('total parameters: %0.2fM' % (total / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(model, dataloader, loss_func, optim, device, kl_weight=0.001, pad_idx=0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: your Conditional VAE\n",
    "        dataloader: yields (zeo, syn, tgt) each step\n",
    "        loss_func: typically nn.CrossEntropyLoss(ignore_index=pad_idx) or similar\n",
    "        optim: torch optimizer\n",
    "        device: 'cuda' or 'cpu'\n",
    "        kl_weight: scaling factor for the KL loss term\n",
    "        pad_idx: optional index for <pad>, used in ignoring pad in cross-entropy\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for i, (zeo, syn, tgt) in enumerate(tqdm(dataloader)):\n",
    "        # Move data to device\n",
    "        zeo = zeo.to(device)\n",
    "        syn = syn.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        # Concatenate to form the full condition\n",
    "        # shape: (batch_size, cond_dim1 + cond_dim2)\n",
    "        condition = torch.cat([zeo, syn], dim=-1)\n",
    "        # tgt: shape (B, seq_len, n_chars) if one-hot approach\n",
    "        tgt_input = tgt[:, :-1].contiguous() # input to the decoder\n",
    "        tgt_target = tgt[:, 1:].contiguous() # target output from the decoder\n",
    "        # convert tgt_input to one -hot code\n",
    "        tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "\n",
    "        # ==========================\n",
    "        # 1) Forward pass\n",
    "        # ==========================\n",
    "        logits, z_mean, z_log_var = model(\n",
    "            x_smi=tgt_input,         # SMILES input\n",
    "            x_cond=condition,  # condition\n",
    "            teacher_force_inputs=tgt_input\n",
    "        )\n",
    "        # logits: shape (B, seq_len, n_chars)\n",
    "        logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "        target_ids = tgt_target.view(-1)  # shape (B * seq_len)\n",
    "        recon_loss = loss_func(logits_reshaped, target_ids)\n",
    "\n",
    "        # ==========================\n",
    "        # 3) Compute KL divergence\n",
    "        # ==========================\n",
    "        # KL = -0.5 * sum(1 + log_var - mean^2 - exp(log_var)) \n",
    "        # We'll average by batch size\n",
    "        kl_loss = -0.5 * torch.sum(\n",
    "            1 + z_log_var - z_mean.pow(2) - z_log_var.exp()\n",
    "        )\n",
    "        kl_loss = kl_loss / tgt.size(0)\n",
    "\n",
    "        # ==========================\n",
    "        # 4) Total loss\n",
    "        # ==========================\n",
    "        loss = recon_loss + kl_weight * kl_loss\n",
    "\n",
    "        # ==========================\n",
    "        # 5) Backprop & update\n",
    "        # ==========================\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # ==========================\n",
    "        # 6) Compute accuracy (optional)\n",
    "        # ==========================\n",
    "        preds = torch.argmax(logits, dim=-1)  # shape (B, seq_len)\n",
    "        num_correct = (preds == tgt_target) & (tgt_target != pad_idx)\n",
    "        num_words = (tgt_target != pad_idx).sum().item()\n",
    "\n",
    "        # ==========================\n",
    "        # 7) Track stats\n",
    "        # ==========================\n",
    "        total_loss += loss.item()\n",
    "        total_acc += num_correct.sum().item()\n",
    "        total_num += num_words\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_acc = total_acc / total_num\n",
    "\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate function\n",
    "def evaluate(model, dataloader, loss_func, device, pad_idx=0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: your Conditional VAE\n",
    "        dataloader: yields (zeo, syn, tgt) each step\n",
    "        loss_func: typically nn.CrossEntropyLoss(ignore_index=pad_idx) or similar\n",
    "        device: 'cuda' or 'cpu'\n",
    "        pad_idx: optional index for <pad>, used in ignoring pad in cross-entropy\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation during testing\n",
    "        for i, (zeo, syn, tgt) in enumerate(tqdm(dataloader)):\n",
    "            # Move data to device\n",
    "            zeo = zeo.to(device)\n",
    "            syn = syn.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            # Concatenate to form the full condition\n",
    "            condition = torch.cat([zeo, syn], dim=-1)\n",
    "            \n",
    "            # tgt: shape (B, seq_len, n_chars) if one-hot approach\n",
    "            tgt_input = tgt[:, :-1].contiguous() # input to the decoder\n",
    "            tgt_target = tgt[:, 1:].contiguous() # target output from the decoder\n",
    "            # convert tgt_input to one -hot code\n",
    "            tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "\n",
    "            # ==========================\n",
    "            # 1) Forward pass\n",
    "            # ==========================\n",
    "            # We use teacher forcing during testing too\n",
    "            logits, z_mean, z_log_var = model(\n",
    "                x_smi=tgt_input,         # SMILES input\n",
    "                x_cond=condition,        # condition\n",
    "                teacher_force_inputs=tgt_input  # Use teacher forcing during inference\n",
    "            )\n",
    "            \n",
    "            # Compute the reconstruction loss\n",
    "            logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "            target_ids = tgt_target.view(-1)\n",
    "            recon_loss = loss_func(logits_reshaped, target_ids)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            num_correct = (preds == tgt_target) & (tgt_target != pad_idx)\n",
    "            num_words = (tgt_target != pad_idx).sum().item()\n",
    "            \n",
    "            # Track stats\n",
    "            total_loss += recon_loss.item()\n",
    "            total_acc += num_correct.sum().item()\n",
    "            total_num += num_words\n",
    "        return total_loss / len(dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc = train(model, train_dataloader, loss_func, optim, device)\n",
    "    test_loss, test_acc = evaluate(model, test_dataloader, loss_func, device)\n",
    "    print('epoch %d, train loss %.4f, train acc %.4f, test loss %.4f, test acc %.4f' % (i, train_loss, train_acc, test_loss, test_acc))\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_acc)\n",
    "    if i == 0:\n",
    "        best_acc = test_acc\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), os.path.join(save_best_weight_path, 'best_cvae_model.pth'))\n",
    "    torch.save(model.state_dict(), os.path.join(save_best_weight_path, 'last_cvae_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cvae(model, condition, tgt_input, vocab, device='cuda', max_len=MAX_LEN, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates SMILES strings from a trained CVAE model, given an already-merged synthesis condition.\n",
    "\n",
    "    Args:\n",
    "        model:       The trained ConditionalVAE model (must implement model.generate).\n",
    "        condition:   (B, cond_dim) - the already-merged condition vector (e.g., torch.cat([zeo, syn], dim=-1)).\n",
    "        tgt_input:   (B, seq_len) - the input SMILES sequence (e.g., the '<sos>' token).\n",
    "        vocab:       The vocabulary object (must implement vocab.idx2char).\n",
    "        device:      'cuda' or 'cpu'.\n",
    "        max_len:     Maximum length of generated SMILES.\n",
    "\n",
    "    Returns:\n",
    "        smiles_list: A list of generated SMILES strings (length = batch size).\n",
    "                     Each string excludes '<sos>', ignores '<pad>', and is cut after '<eos>'.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    smiles_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Move condition to device\n",
    "        condition = condition.to(device)\n",
    "        \n",
    "        # Generate SMILES strings\n",
    "        # Assuming the model has a generate function that takes condition as input\n",
    "        # generated = model.generate(condition, max_len=max_len, device=device, teacher_force_inputs=tgt_input)  # shape: (B, seq_len)\n",
    "        logits, z_mean, z_log = model(\n",
    "            x_smi=tgt_input,         # SMILES input\n",
    "            x_cond=condition,        # condition\n",
    "            teacher_force_inputs=tgt_input  # Use teacher forcing during inference\n",
    "        )\n",
    "\n",
    "        # sample from the logits using multinomial\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        generated = torch.multinomial(probs.view(-1, probs.size(-1)), num_samples=1).view(probs.size(0), probs.size(1))\n",
    "        \n",
    "        \n",
    "        for i in range(generated.size(0)):\n",
    "            # Convert the generated token IDs to SMILES string\n",
    "            smi = []\n",
    "            for idx in generated[i]:\n",
    "                # Convert index to character, skipping padding or other invalid tokens\n",
    "                char = vocab.itos[idx.item()]\n",
    "                if char == '<eos>':  # End of the SMILES string\n",
    "                    break\n",
    "                if char not in ('<sos>', '<pad>'):  # Remove unwanted characters\n",
    "                    smi.append(char)\n",
    "            smiles_list.append(''.join(smi))\n",
    "\n",
    "    return smiles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the smiles for the test dataset\n",
    "generated_smile = []\n",
    "target_smile = []\n",
    "for i, (zeo, syn, tgt) in enumerate(tqdm(train_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1).to(device)\n",
    "    tgt_input = tgt[:, :-1].contiguous()\n",
    "    # convert the tgt_input to one-hot\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=params['NCHARS']).float()\n",
    "    generated_smiles = generate_cvae(model=model, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile.extend(tgt_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics\n",
    "print('Validity rate:', validity_rate(generated_smiles))\n",
    "print('Uniqueness rate:', uniqueness_rate(generated_smiles))\n",
    "print('Novelty rate:', novelty_rate(generated_smiles, target_smile))\n",
    "print('Reconstructability rate:', reconstructability_rate(generated_smiles, target_smile))\n",
    "print('Novelty rate:', novelty_rate(generated_smiles, target_smile))\n",
    "print('IntDiv:', IntDiv(generated_smiles))\n",
    "# print('KL-divergence:', KL_divergence(target_smile), generated_smile))\n",
    "print('FCD score:', FCD_score(target_smile, generated_smile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and acc\n",
    "plot_loss(train_loss_history, test_loss_history, 'cvae')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
