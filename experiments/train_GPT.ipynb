{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with GPT architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hudongcheng/Desktop/bo_osda_generator\n"
     ]
    }
   ],
   "source": [
    "# change working path to the current file\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from models.GPT import *\n",
    "from utils.utils import *\n",
    "from datasets.data_loader import *\n",
    "from utils.plot_figures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "log_dir = './logs/'\n",
    "save_best_weight_path = './checkpoints/'\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the charset(inculde begin end and pad char) achieved from dataset : ?P25$]FO-S.Hc=71(ln63NC4[+)^@\n",
      "the total num of charset is : 29\n"
     ]
    }
   ],
   "source": [
    "# read the data and convert to the format we need\n",
    "train_smiles = read_strings('./data/train_smiles.csv', idx=False)\n",
    "train_zeo = read_vec('./data/train_zeo.csv', idx=False)\n",
    "train_syn = read_vec('./data/train_syn.csv', idx=False)\n",
    "train_codes = read_strings('./data/train_codes.csv', idx=False)\n",
    "test_smiles = read_strings('./data/test_smiles.csv', idx=False)\n",
    "test_zeo = read_vec('./data/test_zeo.csv', idx=False)\n",
    "test_syn = read_vec('./data/test_syn.csv', idx=False)\n",
    "test_codes = read_strings('./data/test_codes.csv', idx=False)\n",
    "\n",
    "charset = '?P25$]FO-S.Hc=71(ln63NC4[+)^@'\n",
    "charlen = len(charset)\n",
    "print('the charset(inculde begin end and pad char) achieved from dataset :', charset)\n",
    "print('the total num of charset is :', charlen)\n",
    "# create the char to index and index to char dictionary\n",
    "char_to_index = dict((c, i) for i, c in enumerate(charset))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(charset))\n",
    "char_list = [k for k, v in char_to_index.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 512\n",
    "epoch = 2\n",
    "seqlen = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 0.84M\n"
     ]
    }
   ],
   "source": [
    "src_smiles, tgt_smiles = smiles_padding(train_smiles)\n",
    "tgt_seq = smiles_to_sequence(tgt_smiles, char_to_index)\n",
    "tgt_seq = torch.cat([torch.unsqueeze(seq, 0) for seq in tgt_seq]).long()\n",
    "src_smiles_test, tgt_smiles_test = smiles_padding(test_smiles)\n",
    "tgt_seq_test = smiles_to_sequence(tgt_smiles_test, char_to_index)\n",
    "tgt_seq_test = torch.cat([torch.unsqueeze(seq, 0) for seq in tgt_seq_test]).long()\n",
    "# create the dataset and dataloader\n",
    "train_dataset = SeqDataset(train_zeo, train_syn, tgt_seq)\n",
    "test_dataset = SeqDataset(test_zeo, test_syn, tgt_seq_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# create the model\n",
    "config = GPTConfig(vocab_size=charlen, block_size=128, num_props=24)\n",
    "model = GPT(config).to(device)\n",
    "# loss\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=char_to_index['?'])\n",
    "optim = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print('total parameters: %0.2fM' % (total / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(model, train_dataloader, loss_func, optim, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    for i, (zeo, syn, tgt) in enumerate(tqdm(train_dataloader)):\n",
    "        zeo = zeo.to(device)\n",
    "        syn = syn.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        # concat zeo and syn as the input (prop)\n",
    "        synthesis_condition = torch.cat([zeo, syn], dim=-1)\n",
    "        tgt_input = tgt[:, :-1].contiguous()\n",
    "        tgt_label = tgt[:, 1:].contiguous()\n",
    "        \n",
    "        # forward\n",
    "        optim.zero_grad()\n",
    "        output = model(idx=tgt_input, prop=synthesis_condition)\n",
    "        loss = loss_func(output.view(-1, output.size(-1)), tgt_label.view(-1))\n",
    "        \n",
    "        # calculate the accuracy\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        num_correct = (pred == tgt_label) & (tgt_label != char_to_index['?'])\n",
    "        num_words = (tgt_label != char_to_index['?']).sum().item()\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += num_correct.sum().item()\n",
    "        total_num += num_words\n",
    "    return total_loss / len(train_dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (zeo, syn, tgt) in enumerate(tqdm(test_dataloader)):\n",
    "            zeo = zeo.to(device)\n",
    "            syn = syn.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            # concat zeo and syn as the input (prop)\n",
    "            synthesis_condition = torch.cat([zeo, syn], dim=-1)\n",
    "            tgt_input = tgt[:, :-1].contiguous()\n",
    "            tgt_label = tgt[:, 1:].contiguous()\n",
    "            # forward\n",
    "            output = model(idx=tgt_input, prop=synthesis_condition)\n",
    "            loss = loss_func(output.view(-1, output.size(-1)), tgt_label.view(-1))\n",
    "            # calculate the accuracy\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            num_correct = (pred == tgt_label) & (tgt_label != char_to_index['?'])\n",
    "            num_words = (tgt_label != char_to_index['?']).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            total_acc += num_correct.sum().item()\n",
    "            total_num += num_words\n",
    "    return total_loss / len(test_dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:08<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.1040, train acc: 0.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 96.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 test loss: 0.8042, test acc: 0.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [00:08<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.7796, train acc: 0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 96.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 test loss: 0.6854, test acc: 0.7414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc = train(model, train_dataloader, loss_func, optim, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    print('epoch: %d, train loss: %.4f, train acc: %.4f' % (i, train_loss, train_acc))\n",
    "    test_loss, test_acc = evaluate(model, test_dataloader, loss_func, device)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_acc)\n",
    "    print('epoch: %d test loss: %.4f, test acc: %.4f' % (i, test_loss, test_acc))\n",
    "    if i == 0:\n",
    "        best_acc = test_acc\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_best_weight_path + 'best_GPT_model.pth')\n",
    "    torch.save(model.state_dict(), save_best_weight_path + 'last_GPT_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt(model, start_sequence, condition_props, max_length, char_to_index, index_to_char, device, temperature=1.0, top_k=0):\n",
    "    \"\"\"\n",
    "    Autoregressive generation process for a GPT model.\n",
    "\n",
    "    Args:\n",
    "        model (GPT): The pre-trained GPT model for token generation.\n",
    "        start_sequence (torch.Tensor): The initial sequence to start generation (batch_size, seq_length).\n",
    "        condition_props (torch.Tensor): The conditional property vector (batch_size, num_props).\n",
    "        max_length (int): The maximum length of the generated sequence.\n",
    "        char_to_index (dict): A mapping from characters to their corresponding indices.\n",
    "        index_to_char (dict): A mapping from indices to their corresponding characters.\n",
    "        device (torch.device): The device on which to run the generation.\n",
    "        temperature (float): Temperature parameter for sampling; higher values increase randomness.\n",
    "        top_k (int): Limits sampling to top-k logits; if 0, no top-k sampling is applied.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of generated SMILES strings.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch_size = start_sequence.size(0)\n",
    "    generated_sequences = start_sequence.clone().to(device)  # Clone and move to device\n",
    "\n",
    "    for _ in range(max_length - start_sequence.size(1)):\n",
    "        # Get the current sequence length\n",
    "        current_length = generated_sequences.size(1)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        logits = model(generated_sequences, condition_props)  # (batch_size, seq_length, vocab_size)\n",
    "\n",
    "        # Extract the logits for the last time step\n",
    "        next_token_logits = logits[:, -1, :]  # (batch_size, vocab_size)\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        next_token_logits = next_token_logits / temperature\n",
    "\n",
    "        # Apply top-k filtering\n",
    "        if top_k > 0:\n",
    "            top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k, dim=-1)\n",
    "            mask = torch.full_like(next_token_logits, float('-inf'))\n",
    "            mask.scatter_(dim=-1, index=top_k_indices, src=top_k_logits)\n",
    "            next_token_logits = mask\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "        # Sample from the probability distribution\n",
    "        next_token = torch.multinomial(next_token_probs, num_samples=1)  # (batch_size, 1)\n",
    "        \n",
    "        # Get the most likely next token\n",
    "        # next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "\n",
    "        # Append the generated token to the sequence\n",
    "        generated_sequences = torch.cat([generated_sequences, next_token], dim=1)\n",
    "\n",
    "        # Check if all sequences have reached the end token ('$')\n",
    "        if all(next_token[i].item() == char_to_index['$'] for i in range(batch_size)):\n",
    "            break\n",
    "\n",
    "    # Decode the generated sequences into SMILES strings\n",
    "    generated_smiles = []\n",
    "    for seq in generated_sequences:\n",
    "        # Convert indices to characters, ignoring padding ('?') and start ('^') tokens\n",
    "        # check if the generated sequence contains the end token ('$'), if meet, stop decoding\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == char_to_index['$']:\n",
    "                break\n",
    "            elif idx.item() != char_to_index['?'] and idx.item() != char_to_index['^']:\n",
    "                smiles += index_to_char[idx.item()]\n",
    "        generated_smiles.append(smiles)\n",
    "\n",
    "    return generated_smiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target smiles:\n",
      "[['n1(C)c(C)[n+](cc1)Cc1ccccc1C[n+]1ccn(C)c1C']\n",
      " ['Cn1cc[n+](Cc2ccccc2C[n+]2ccn(C)c2C)c1C']\n",
      " ['Cc1n(C)cc[n+]1Cc1c(cccc1)C[n+]1ccn(c1C)C']\n",
      " ['c1ccc(c(c1)C[n+]1c(C)n(C)cc1)C[n+]1ccn(c1C)C']\n",
      " ['[n+]1(c(n(C)cc1)C)Cc1c(C[n+]2ccn(c2C)C)cccc1']\n",
      " ['Cc1n(C)cc[n+]1Cc1ccccc1C[n+]1c(n(cc1)C)C']\n",
      " ['Cn1c(C)[n+](cc1)Cc1ccccc1C[n+]1ccn(c1C)C']\n",
      " ['c1c[n+](Cc2ccccc2C[n+]2c(C)n(cc2)C)c(C)n1C']\n",
      " ['n1(cc[n+](c1C)Cc1ccccc1C[n+]1ccn(C)c1C)C']\n",
      " ['[n+]1(Cc2c(C[n+]3c(n(cc3)C)C)cccc2)c(C)n(C)cc1']]\n",
      "generated smiles:\n",
      "['C(CCCCCCCCCC[N+](C)(C)C)(C)C', 'c1cn(C[n+]2c(ccccc2)C)C1c(n1)C', '[n+]1(ccn(c1C)C)CCCC[n+]1cc(n(C)cc1C)C', 'c1ccc(C[n+]2cc(c2)C)ccc(n1)C', 'c1(C[n+]2c(n(cc2)C)cccc1)C[n+]1cn(c(n(C)c1C)C)C', 'C(CC[n+]1cccnN(C)c1)CC', 'c1cccn([n+]2cn(C)c(C)n2C)ccc(C)cc1', 'Cc1[n+](CCCCc2)cc(n(C)c2)C)c(C)=C1', 'c1cc(cc(C)n(c1)C)[n+]1Cc(n(C)cc1)C', '[n+]1(Cc(n(C)cc1)Cccc1)CCCC[n+]1cn(c(C)C)c1C']\n"
     ]
    }
   ],
   "source": [
    "# test the generate function\n",
    "# check the first 10 samples\n",
    "train_zeo = train_zeo[:10].astype(np.float32)\n",
    "train_syn = train_syn[:10].astype(np.float32)\n",
    "zeo = torch.tensor(train_zeo, dtype=torch.float32).to(device)\n",
    "syn = torch.tensor(train_syn, dtype=torch.float32).to(device)\n",
    "target_smi = train_smiles[:10]\n",
    "start_sequence = torch.full((10, 1), char_to_index['^'], dtype=torch.long)\n",
    "start_sequence = start_sequence.to(device)\n",
    "condition_synthesis = torch.cat([zeo, syn], dim=1)\n",
    "generated_smiles = generate_gpt(model, start_sequence, condition_synthesis, seqlen, char_to_index, index_to_char, device)\n",
    "print('target smiles:')\n",
    "print(target_smi)\n",
    "print('generated smiles:')\n",
    "print(generated_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss and acc\n",
    "plot_loss(train_loss_history, test_loss_history, 'GPT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
