{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clamer generate the moleculars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hudongcheng/Desktop/bo_osda_generator\n"
     ]
    }
   ],
   "source": [
    "# change the working path\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "from models.clamer import GptCovd\n",
    "from configs.config_clamer import config\n",
    "from utils.data_processing import data_augment, norm, data_sift\n",
    "from datasets.data_loader import SampleDataset\n",
    "from utils.utils import data_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741 191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data path\n",
    "log_dir = './logs/'\n",
    "save_best_weight_path = './checkpoints/'\n",
    "sample_loss_history = []\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "data_file = r'./data/OSDA_ZEO.xlsx'\n",
    "model_file = r'./checkpoints/NO.0-2024-12-18-16-58-50-0.275966-0.15.pth'\n",
    "\n",
    "# read data\n",
    "data = pd.read_excel(data_file, engine='openpyxl')\n",
    "smiles_aug, zeo_features_aug, syn_features_aug, codes_aug = data_augment(augment=False, data=data)\n",
    "\n",
    "zeo_features = np.array(zeo_features_aug)\n",
    "zeo_features = norm(zeo_features)\n",
    "\n",
    "smiles, zeo_vectors, syn_vectors, codes = data_sift(smiles_aug, zeo_features, syn_features_aug, codes_aug)\n",
    "print(len(set(smiles)), len(set(codes)))\n",
    "unique_codes = ['AFI']\n",
    "split = \"AFI\"\n",
    "_, _, _, _, test_smiles, test_zeo, test_syn, _ = data_split(split, unique_codes,\n",
    "                                                                        smiles, zeo_vectors, syn_vectors, codes)\n",
    "test_smiles = test_smiles * 250\n",
    "test_zeo = test_zeo * 250  # * 121 42\n",
    "test_syn = test_syn * 250  # * 121 42\n",
    "ref_smiles = test_smiles[0:1000]\n",
    "sample_zeo = test_zeo[0:1000]\n",
    "sample_syn = test_syn[0:1000]\n",
    "sample_dataset = SampleDataset(sample_zeo, sample_syn)\n",
    "# print('samples of testset without augmented is: ', len(train_dataset))\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=config().batch_size, shuffle=False, collate_fn=None, pin_memory=True)\n",
    "\n",
    "# load model\n",
    "model = GptCovd(d_model=config().d_model, \n",
    "                charlen=config().charlen,\n",
    "                device=config().device,\n",
    "                head=config().head,\n",
    "                char_to_index=config().char_to_index).to(config().device)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_file,  map_location=torch.device('cuda:0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gpt(epochs, temp):\n",
    "    writer = SummaryWriter(log_dir=log_dir, flush_secs=60)\n",
    "    sample_nll_total = []\n",
    "    smiles_gen_total = []\n",
    "    for epoch in range(epochs):\n",
    "        bar = tqdm(total=len(sample_dataloader), ncols=125)\n",
    "        bar.set_description_str(f\"{epoch}/{epochs}\")\n",
    "\n",
    "        for batch_idx, (zeo, syn) in enumerate(sample_dataloader):\n",
    "            with torch.no_grad():\n",
    "                target = [config().char_to_index['^']] + [config().char_to_index['?']] * 124\n",
    "                tgt_seq = torch.LongTensor(target).unsqueeze(0).expand(zeo.size(0), len(target)).to(config().device)\n",
    "\n",
    "                zeo, syn = zeo.to(config().device), syn.to(config().device)\n",
    "                smiles_gen = [[''] * config().batch_size][0]\n",
    "                sample_nll = [0] * config().batch_size\n",
    "                finished = np.array([False] * config().batch_size, dtype=object)\n",
    "                end_char = '$'\n",
    "                for i in range(124):\n",
    "                    net_out = model(zeo, syn, tgt_seq)[:, i + 2, :]\n",
    "                    o = F.softmax(net_out, dim=-1).cpu().detach().numpy()\n",
    "                    # sample temp\n",
    "                    if temp != 0:\n",
    "                        temp = abs(temp)  # No negative values\n",
    "                        next_char_probs = np.log(o) / temp\n",
    "                        next_char_probs = np.exp(next_char_probs)\n",
    "                        next_char_probs = next_char_probs.astype(float)\n",
    "                        next_char_probs = (next_char_probs.T / (next_char_probs.sum(axis=1))).T\n",
    "                        sampleidc = torch.tensor(\n",
    "                            [np.random.multinomial(1, next_char_prob, 1).argmax() for next_char_prob in\n",
    "                             next_char_probs])\n",
    "                    else:\n",
    "                        sampleidc = torch.tensor(np.argmax(o, axis=1))\n",
    "\n",
    "                    samplechars = [config().index_to_char[idx] for idx in sampleidc.numpy()]\n",
    "\n",
    "                    for idx, samplechar in enumerate(samplechars):\n",
    "                        if not finished[idx]:\n",
    "                            if samplechar != end_char:\n",
    "                                # Append the SMILES with the next character\n",
    "                                smiles_gen[idx] += samplechar\n",
    "                                tgt_seq[:, i + 1] = sampleidc.to(config().device)\n",
    "                                # Calculate negative log likelihood for the selected character\n",
    "                                sample_nll[idx] -= np.log(o[idx][sampleidc[idx]])\n",
    "                            else:\n",
    "                                finished[idx] = True\n",
    "                                # print(\"SMILES has finished at %i\" %i)\n",
    "                    # If all SMILES are finished, i.e. the end_char \"$\" has been generated, stop the generation\n",
    "                if finished.sum() == len(finished):\n",
    "                    sample_nll_total += sample_nll\n",
    "                    smiles_gen_total += smiles_gen\n",
    "                bar.update()\n",
    "\n",
    "        print('finished')\n",
    "        bar.update()\n",
    "        bar.close()\n",
    "\n",
    "    writer.close()\n",
    "    return sample_nll_total, smiles_gen_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成采样\n",
    "sam_null, sam_text = sample_gpt(1, 1)\n",
    "# 评估分子有效性\n",
    "valid_smiles_ref = []\n",
    "valid_smiles_sam = []\n",
    "valid_smiles_null = []\n",
    "valid_zeos = []\n",
    "valid_syns = []\n",
    "for i, (r, s, n, z, y) in enumerate(zip(ref_smiles, sam_text, sam_null, sample_zeo, sample_syn)):\n",
    "    try:\n",
    "        mol_ge = Chem.MolFromSmiles(s)\n",
    "        if mol_ge is not None:\n",
    "            valid_smiles_sam.append(s)\n",
    "            valid_smiles_null.append(n)\n",
    "            valid_smiles_ref.append(r)\n",
    "            valid_zeos.append(z)\n",
    "            valid_syns.append(y)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print('total valid smiles num: ', len(valid_smiles_sam))\n",
    "print('unique smilee num: ', len(set(valid_smiles_sam)))\n",
    "df({'mol_gen': valid_smiles_sam, 'smiles': valid_smiles_ref, 'zeos': valid_zeos, 'syns': valid_syns,\n",
    "        'valid_smiles_null': valid_smiles_null, }).to_csv('AFI_gpt6lmpad_sample497.csv')  # aei_train_sample_gpt6lm02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
