{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from datasets.data_loader import *\n",
    "from models.clamer import *\n",
    "from models.loss import InfoNCELoss\n",
    "from models.trfm import *\n",
    "from utils.utils import *\n",
    "from utils.plot_figures import *\n",
    "from utils.metrics import *\n",
    "from utils.build_vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.build_vocab import WordVocab\n",
    "from models.trfm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_clamer(temp, model, sample_dataloader, device, vocab):\n",
    "    '''ArithmeticError\n",
    "    Generate SMILES strings using the trained GPT model with sampling.\n",
    "    \n",
    "    Args:\n",
    "        temp (float): The temperature parameter for sampling.\n",
    "        model (CLAMER): The pre-trained GPT model for token generation.\n",
    "        sample_dataloader (DataLoader): The data loader for the SMILES dataset.\n",
    "        device (torch.device): The device on which to run the generation.\n",
    "        vocab: The vocabulary object for encoding and decoding SMILES strings.\n",
    "    \n",
    "    Returns:\n",
    "        List[float]: A list of negative log-likelihoods for the generated SMILES strings.\n",
    "        List[str]: A list of generated SMILES strings.\n",
    "    '''\n",
    "    sample_nll_total = []\n",
    "    smiles_gen_total = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (zeo, syn, tgt) in enumerate(tqdm(sample_dataloader)):\n",
    "            # Generate the target sequence for the model\n",
    "            target = [SOS] + [PAD] * 218\n",
    "            tgt_seq = torch.LongTensor(target).unsqueeze(0).expand(zeo.size(0), len(target)).to(device)\n",
    "            batch_size = zeo.size(0)\n",
    "            # Move input tensors to the device\n",
    "            zeo, syn = zeo.to(device), syn.to(device)\n",
    "            smiles_gen = [[''] * batch_size][0]\n",
    "            sample_nll = [0] * batch_size\n",
    "            finished = np.array([False] * batch_size, dtype=object)\n",
    "            end_char = '<eos>'\n",
    "            for i in range(218):\n",
    "                net_out = model(zeo, syn, tgt_seq)[:, i + 2, :]\n",
    "                o = F.softmax(net_out, dim=-1).cpu().detach().numpy()\n",
    "                # sample temp\n",
    "                if temp != 0:\n",
    "                    temp = abs(temp)  # No negative values\n",
    "                    next_char_probs = np.log(o) / temp\n",
    "                    next_char_probs = np.exp(next_char_probs)\n",
    "                    next_char_probs = next_char_probs.astype(float)\n",
    "                    next_char_probs = (next_char_probs.T / (next_char_probs.sum(axis=1))).T\n",
    "                    sampleidc = torch.tensor(\n",
    "                        [np.random.multinomial(1, next_char_prob, 1).argmax() for next_char_prob in\n",
    "                            next_char_probs])\n",
    "                else:\n",
    "                    sampleidc = torch.tensor(np.argmax(o, axis=1))\n",
    "\n",
    "                samplechars = [vocab.itos[idx] for idx in sampleidc.numpy()]\n",
    "\n",
    "                for idx, samplechar in enumerate(samplechars):\n",
    "                    if not finished[idx]:\n",
    "                        if samplechar != end_char:\n",
    "                            # Append the SMILES with the next character\n",
    "                            smiles_gen[idx] += samplechar\n",
    "                            tgt_seq[:, i + 1] = sampleidc.to(device)\n",
    "                            # Calculate negative log likelihood for the selected character\n",
    "                            sample_nll[idx] -= np.log(o[idx][sampleidc[idx]])\n",
    "                        else:\n",
    "                            finished[idx] = True\n",
    "                            # print(\"SMILES has finished at %i\" %i)\n",
    "                # If all SMILES are finished, i.e. the end_char \"<eos>\" has been generated, stop the generation\n",
    "            if finished.sum() == len(finished):\n",
    "                sample_nll_total += sample_nll\n",
    "                smiles_gen_total += smiles_gen\n",
    "                    \n",
    "    return sample_nll_total, smiles_gen_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "AFI_smiles = read_strings('./data_AFI/AFI_smiles.csv', idx=False)\n",
    "AFI_zeo = read_vec('./data_AFI/AFI_zeo.csv', idx=False)\n",
    "AFI_syn = read_vec('./data_AFI/AFI_syn.csv', idx=False)\n",
    "CHA_smiles = read_strings('./data_CHA/CHA_smiles.csv', idx=False)\n",
    "CHA_zeo = read_vec('./data_CHA/CHA_zeo.csv', idx=False)\n",
    "CHA_syn = read_vec('./data_CHA/CHA_syn.csv', idx=False)\n",
    "AEI_smiles = read_strings('./data_AEI/AEI_smiles.csv', idx=False)\n",
    "AEI_zeo = read_vec('./data_AEI/AEI_zeo.csv', idx=False)\n",
    "AEI_syn = read_vec('./data_AEI/AEI_syn.csv', idx=False)\n",
    "train_smiles = read_strings('./data/train_smiles.csv', idx=False)\n",
    "test_smiles = read_strings('./data/test_smiles.csv', idx=False)\n",
    "# merge the training and testing smiles, thay\n",
    "train_smiles = train_smiles.tolist()\n",
    "test_smiles = test_smiles.tolist()\n",
    "train_smiles = [i[0] for i in train_smiles]\n",
    "test_smiles = [i[0] for i in test_smiles]\n",
    "all_smiles = train_smiles + test_smiles\n",
    "print(all_smiles[:5])\n",
    "\n",
    "vocab = WordVocab.load_vocab('./model_hub/vocab.pkl')\n",
    "print('the vocab size is :', len(vocab))\n",
    "\n",
    "charlen = len(vocab)\n",
    "print('the total num of charset is :', charlen)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "batch_size = 64\n",
    "\n",
    "manual_seed = 42\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create the dataset and dataloader\n",
    "AFI_dataset = Seq2seqDataset(AFI_zeo, AFI_syn, AFI_smiles, vocab)\n",
    "CHA_dataset = Seq2seqDataset(CHA_zeo, CHA_syn, CHA_smiles, vocab)\n",
    "AEI_dataset = Seq2seqDataset(AEI_zeo, AEI_syn, AEI_smiles, vocab)\n",
    "AFI_dataloader = DataLoader(AFI_dataset, batch_size=batch_size, shuffle=True)\n",
    "CHA_dataloader = DataLoader(CHA_dataset, batch_size=batch_size, shuffle=False)\n",
    "AEI_dataloader = DataLoader(AEI_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = 0\n",
    "unk_index = 1\n",
    "eos_index = 2\n",
    "sos_index = 3\n",
    "mask_index = 4\n",
    "\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "EOS = 2\n",
    "SOS = 3\n",
    "MASK = 4\n",
    "MAX_LEN = 220\n",
    "\n",
    "# load model\n",
    "# trfm = TrfmSeq2seq(charlen, 256, charlen, 4).to(device)\n",
    "trfm = TrfmSeq2seq(charlen, 256, charlen, 4)\n",
    "trfm.load_state_dict(torch.load('./model_hub/trfm_new_2_10000.pkl'))\n",
    "trfm.eval()\n",
    "\n",
    "# set trfm gradient to false which won't be updated\n",
    "for param in trfm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# calculate the number of parameters\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in trfm.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "head = 4\n",
    "\n",
    "model = GptCovd(d_model=d_model, charlen=charlen, device=device, head=head)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate(path, model, dataloader, device, vocab):\n",
    "#     model = load_model(model, path)\n",
    "#     model.eval()\n",
    "#     nll, generate_smiles = sample_clamer(0.5, model, dataloader, device, vocab)\n",
    "#     return nll, generate_smiles\n",
    "\n",
    "# # generate the smiles\n",
    "# AFI_generate_smiles = pd.DataFrame()\n",
    "# for i in range(6):\n",
    "#     path = './checkpoints/clamer/clamer_contrastive_model_{}.pth'.format(i)\n",
    "#     nll, smiles = generate(path, model, AFI_dataloader, device, vocab)\n",
    "#     smiles = pd.DataFrame(smiles, columns=['epoch_{}'.format(i)])\n",
    "#     AFI_generate_smiles = pd.concat([AFI_generate_smiles, smiles], axis=1)\n",
    "\n",
    "# # save the generated smiles\n",
    "# AFI_generate_smiles.to_csv('./generation/AFI_generate_smiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHA_generate_smiles = pd.DataFrame()\n",
    "# for i in range(6):\n",
    "#     path = './checkpoints/clamer/clamer_contrastive_model_{}.pth'.format(i)\n",
    "#     nll, smiles = generate(path, model, CHA_dataloader, device, vocab)\n",
    "#     smiles = pd.DataFrame(smiles, columns=['epoch_{}'.format(i)])\n",
    "#     CHA_generate_smiles = pd.concat([CHA_generate_smiles, smiles], axis=1)\n",
    "\n",
    "# # save the generated smiles\n",
    "# CHA_generate_smiles.to_csv('./generation/CHA_generate_smiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEI_generate_smiles = pd.DataFrame()\n",
    "# for i in range(6):\n",
    "#     path = './checkpoints/clamer/clamer_contrastive_model_{}.pth'.format(i)\n",
    "#     nll, smiles = generate(path, model, AEI_dataloader, device, vocab)\n",
    "#     smiles = pd.DataFrame(smiles, columns=['epoch_{}'.format(i)])\n",
    "#     AEI_generate_smiles = pd.concat([AEI_generate_smiles, smiles], axis=1)\n",
    "\n",
    "# # save the generated smiles\n",
    "# AEI_generate_smiles.to_csv('./generation/AEI_generate_smiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_vec(Smiles, vocab, trfm):\n",
    "    def get_inputs(sm):\n",
    "        seq_len = 220\n",
    "        sm = sm.split()\n",
    "        if len(sm)>218:\n",
    "            print('SMILES is too long ({:d})'.format(len(sm)))\n",
    "            sm = sm[:109]+sm[-109:]\n",
    "        ids = [vocab.stoi.get(token, unk_index) for token in sm]\n",
    "        ids = [sos_index] + ids + [eos_index]\n",
    "        seg = [1]*len(ids)\n",
    "        padding = [pad_index]*(seq_len - len(ids))\n",
    "        ids.extend(padding), seg.extend(padding)\n",
    "        return ids, seg\n",
    "    def get_array(smiles):\n",
    "        x_id, x_seg = [], []\n",
    "        for sm in smiles:\n",
    "            a,b = get_inputs(sm)\n",
    "            x_id.append(a)\n",
    "            x_seg.append(b)\n",
    "        return torch.tensor(x_id), torch.tensor(x_seg)\n",
    "    x_split = [split(sm) for sm in Smiles]\n",
    "    xid, xseg = get_array(x_split)\n",
    "    # xid = xid.to(device)\n",
    "    X = trfm.encode(torch.t(xid))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the generated smiles\n",
    "AFI_generate_smiles = pd.read_csv('./generation/AFI_generate_smiles.csv')\n",
    "CHA_generate_smiles = pd.read_csv('./generation/CHA_generate_smiles.csv')\n",
    "AEI_generate_smiles = pd.read_csv('./generation/AEI_generate_smiles.csv')\n",
    "all_smiles_unique = pd.read_csv('./data/all_smiles_unique.csv')\n",
    "\n",
    "def validity_smiles(smiles):\n",
    "    valid = []\n",
    "    for smile in smiles:\n",
    "        try:\n",
    "            Chem.MolFromSmiles(smile)\n",
    "            valid.append(smile)\n",
    "        except:\n",
    "            continue\n",
    "    return valid\n",
    "\n",
    "# get the valid smiles\n",
    "AFI_generate_smiles = AFI_generate_smiles.apply(validity_smiles)\n",
    "CHA_generate_smiles = CHA_generate_smiles.apply(validity_smiles)\n",
    "AEI_generate_smiles = AEI_generate_smiles.apply(validity_smiles)\n",
    "# all_smiles_unique = all_smiles_unique.apply(validity_smiles)\n",
    "\n",
    "def random_sample(df, n):\n",
    "    df_sample = pd.DataFrame()\n",
    "    for i in range(6):\n",
    "        smiles = df['epoch_{}'.format(i)]\n",
    "        smiles = random.sample(smiles, n)\n",
    "        smiles = pd.DataFrame(smiles, columns=['epoch_{}'.format(i)])\n",
    "        df_sample = pd.concat([df_sample, smiles], axis=1)\n",
    "    return df_sample\n",
    "    \n",
    "\n",
    "AFI_generate_smiles = random_sample(AFI_generate_smiles, 50)\n",
    "CHA_generate_smiles = random_sample(CHA_generate_smiles, 50)\n",
    "AEI_generate_smiles = random_sample(AEI_generate_smiles, 50)\n",
    "\n",
    "def get_vec(df, vocab, trfm, epoch):\n",
    "    df_smiles = df['epoch_{}'.format(epoch)]\n",
    "    if isinstance(df_smiles, pd.Series):\n",
    "        df_smiles = df_smiles.tolist()\n",
    "    # convert the smiles to vec\n",
    "    vec = smiles_to_vec(df_smiles, vocab, trfm)\n",
    "    return vec\n",
    "\n",
    "# get the vec for the generated smiles\n",
    "# AFI_generated_vec = get_vec(AFI_generate_smiles, vocab, trfm, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the all_smiles_unique\n",
    "# every smiles generate 10 new smiles\n",
    "def smiles_randomize(smiles, num=10):\n",
    "    new_smiles = []\n",
    "    for i in range(len(smiles)):\n",
    "        for j in range(num):\n",
    "            # using rdkit to randomize the smiles\n",
    "            mol = Chem.MolFromSmiles(smiles[i])\n",
    "            if mol is None:\n",
    "                continue\n",
    "            new_smiles.append(Chem.MolToSmiles(mol, canonical=False))\n",
    "    return new_smiles\n",
    "\n",
    "all_smiles = [smiles for smiles in all_smiles_unique['smiles']]\n",
    "print(all_smiles[:5])\n",
    "print(type(all_smiles))\n",
    "all_smiles = smiles_randomize(all_smiles)\n",
    "print(len(all_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert AFI, AEI, CHA to list like ['CCO', 'CCN']\n",
    "AFI_smiles = AFI_smiles.tolist()\n",
    "AFI_smiles = [i[0] for i in AFI_smiles]\n",
    "print(AFI_smiles[:5])\n",
    "CHA_smiles = CHA_smiles.tolist()\n",
    "CHA_smiles = [i[0] for i in CHA_smiles]\n",
    "AEI_smiles = AEI_smiles.tolist()\n",
    "AEI_smiles = [i[0] for i in AEI_smiles]\n",
    "\n",
    "# randomize the AFI, AEI, CHA smiles\n",
    "AFI_smiles = smiles_randomize(AFI_smiles, 20)\n",
    "CHA_smiles = smiles_randomize(CHA_smiles, 20)\n",
    "AEI_smiles = smiles_randomize(AEI_smiles, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the smiles to vec\n",
    "all_vec = smiles_to_vec(all_smiles, vocab, trfm)\n",
    "print(all_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降维函数\n",
    "def PCA_reduce(data, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(data)\n",
    "\n",
    "def tSNE_reduce(data, n_components=2):\n",
    "    tsne = TSNE(n_components=n_components)\n",
    "    return tsne.fit_transform(data)\n",
    "\n",
    "def UMAP_reduce(data, n_components=2):\n",
    "    umap = UMAP(n_components=n_components)\n",
    "    return umap.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_scatter_epochs(all_vec, origin_smiles, generated_smiles, method='PCA', epochs=10):\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, epochs, figsize=(18, 5), dpi=300)\n",
    "    \n",
    "#     # remove all charts border\n",
    "#     for ax in axes:\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.spines['bottom'].set_visible(False)\n",
    "#         ax.spines['left'].set_visible(False)\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "    \n",
    "#     # convert origin_smiles to vec\n",
    "#     origin_vec = smiles_to_vec(origin_smiles, vocab, trfm)\n",
    "#     # reduce the dimension\n",
    "#     if method == 'PCA':\n",
    "#         origin_vec = PCA_reduce(origin_vec)\n",
    "#         all_vec = PCA_reduce(all_vec)\n",
    "#     elif method == 'tSNE':\n",
    "#         origin_vec = tSNE_reduce(origin_vec)\n",
    "#         all_vec = tSNE_reduce(all_vec)\n",
    "#     elif method == 'UMAP':\n",
    "#         origin_vec = UMAP_reduce(origin_vec)\n",
    "#         all_vec = UMAP_reduce(all_vec)\n",
    "    \n",
    "#     for i in range(epochs):\n",
    "#         # get generated smiles vec\n",
    "#         generated_vec = get_vec(generated_smiles, vocab, trfm, i)\n",
    "#         # reduce the dimension\n",
    "#         if method == 'PCA':\n",
    "#             generated_vec = PCA_reduce(generated_vec)\n",
    "#         elif method == 'tSNE':\n",
    "#             generated_vec = tSNE_reduce(generated_vec)  \n",
    "#         elif method == 'UMAP':\n",
    "#             generated_vec = UMAP_reduce(generated_vec)\n",
    "#         # draw the scatter plot\n",
    "#         axes[i].scatter(all_vec[:, 0], all_vec[:, 1], c='grey', s=5, label='All OSDAs SMILES')\n",
    "#         axes[i].scatter(origin_vec[:, 0], origin_vec[:, 1], c='blue', s=5, label='Source SMILES')\n",
    "#         axes[i].scatter(generated_vec[:, 0], generated_vec[:, 1], c='red', s=5, label='Generated SMILES')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatter_epochs(all_vec, origin_smiles, generated_smiles, method='PCA', epochs=10, cmap='coolwarm', alpha=0.7):\n",
    "    \"\"\"\n",
    "    Draws scatter plots for dimensionality reduction of SMILES vectors over multiple epochs.\n",
    "\n",
    "    Parameters:\n",
    "        all_vec (numpy.ndarray): The complete vector representation of all SMILES.\n",
    "        origin_smiles (list): The source SMILES strings.\n",
    "        generated_smiles (list): The generated SMILES strings.\n",
    "        method (str): The dimensionality reduction method ('PCA', 'tSNE', or 'UMAP').\n",
    "        epochs (int): Number of epochs to show.\n",
    "        cmap (str): Color map for distinguishing between SMILES types.\n",
    "        alpha (float): Transparency level for scatter points.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, epochs, figsize=(18, 4), dpi=300)\n",
    "\n",
    "    # Remove all chart borders and ticks\n",
    "    for ax in axes:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Convert origin_smiles to vector representations\n",
    "    origin_vec = smiles_to_vec(origin_smiles, vocab, trfm)\n",
    "    \n",
    "    # Apply the chosen dimensionality reduction method\n",
    "    if method == 'PCA':\n",
    "        origin_vec = PCA_reduce(origin_vec)\n",
    "        all_vec = PCA_reduce(all_vec)\n",
    "    elif method == 'tSNE':\n",
    "        origin_vec = tSNE_reduce(origin_vec)\n",
    "        all_vec = tSNE_reduce(all_vec)\n",
    "    elif method == 'UMAP':\n",
    "        origin_vec = UMAP_reduce(origin_vec)\n",
    "        all_vec = UMAP_reduce(all_vec)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Get the generated SMILES vector for the current epoch\n",
    "        generated_vec = get_vec(generated_smiles, vocab, trfm, i)\n",
    "\n",
    "        # Apply the chosen dimensionality reduction method to the generated SMILES vectors\n",
    "        if method == 'PCA':\n",
    "            generated_vec = PCA_reduce(generated_vec)\n",
    "        elif method == 'tSNE':\n",
    "            generated_vec = tSNE_reduce(generated_vec)\n",
    "        elif method == 'UMAP':\n",
    "            generated_vec = UMAP_reduce(generated_vec)\n",
    "\n",
    "        # Scatter plot for all vectors (grey)\n",
    "        axes[i].scatter(all_vec[:, 0], all_vec[:, 1], c='grey', s=7, alpha=alpha, label='All OSDAs SMILES')\n",
    "\n",
    "        # Scatter plot for origin vectors (blue)\n",
    "        axes[i].scatter(origin_vec[:, 0], origin_vec[:, 1], c='blue', s=15, alpha=alpha, label='Source SMILES')\n",
    "\n",
    "        # Scatter plot for generated vectors (red)\n",
    "        axes[i].scatter(generated_vec[:, 0], generated_vec[:, 1], c='red', s=15, alpha=alpha, label='Generated SMILES')\n",
    "\n",
    "        # # Add a legend with reduced font size for clarity\n",
    "        # axes[i].legend(loc='upper right', fontsize=8)\n",
    "\n",
    "        # # Set aspect ratio to be equal\n",
    "        # axes[i].set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Fine-tune the layout for better spacing and figure tightness\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the scatter plotfor AFI\n",
    "draw_scatter_epochs(all_vec, AFI_smiles, AFI_generate_smiles, method='PCA', epochs=6)\n",
    "draw_scatter_epochs(all_vec, AEI_smiles, AEI_generate_smiles, method='PCA', epochs=6)\n",
    "draw_scatter_epochs(all_vec, CHA_smiles, CHA_generate_smiles, method='PCA', epochs=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
