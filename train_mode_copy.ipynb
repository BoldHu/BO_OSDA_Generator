{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换到当前目录\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from build_vocab import WordVocab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataset.dataset import ZeoliteDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from model import LSTM_Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "pad_index = 0\n",
    "unk_index = 1\n",
    "eos_index = 2\n",
    "sos_index = 3\n",
    "mask_index = 4\n",
    "\n",
    "# load vocabulary\n",
    "vocab = WordVocab.load_vocab('models/vocab.pkl')\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# path to the training and testing data\n",
    "train_data_path = 'data/zeolite_train.csv'\n",
    "test_data_path = 'data/zeolite_train.csv'\n",
    "\n",
    "cudnn.benchmark = True\n",
    "lr = 1e-4\n",
    "batch_size = 512\n",
    "n_epoch = 10\n",
    "\n",
    "manual_seed = 42\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# load the training and testing data\n",
    "train_dataset = ZeoliteDataset(train_data_path)\n",
    "test_dataset = ZeoliteDataset(test_data_path)\n",
    "\n",
    "# create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=32)\n",
    "\n",
    "# load the model\n",
    "model = LSTM_Variant(vocab_size, embedding_dim=128, hidden_dim=256, conditional_synthesis_dim=24, num_layers=2, dropout=0.5)\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training and testing functions\n",
    "def sample_from_logits(logits, temperature=1.0):\n",
    "    logits = logits / temperature  # (batch_size, vocab_size)\n",
    "    probs = F.softmax(logits, dim=-1)  # (batch_size, vocab_size)\n",
    "    return torch.multinomial(probs, num_samples=1).squeeze(-1)  # (batch_size,)\n",
    "\n",
    "def vocab_to_smiles(vocab, matrix):\n",
    "    smiles = []\n",
    "    # matrix: (batch_size, seq_len)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        # convert the matrix to a list of words and pad index\n",
    "        words = []\n",
    "        for j in range(matrix.shape[1]):\n",
    "            if matrix[i, j] == pad_index:\n",
    "                break\n",
    "            words.append(vocab.itos[matrix[i, j]])\n",
    "        # remove the sos and eos tokens\n",
    "        words = words[1:-1]\n",
    "        # convert the list of words to a string\n",
    "        smiles.append(''.join(words))\n",
    "    return smiles\n",
    "\n",
    "def train(epoches, model, iterator, optimizer, criterion, device):\n",
    "    # teaching forcing\n",
    "    epoch_loss = 0\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    for epoch in range(epoches):\n",
    "        model.train()\n",
    "        for i, (conditional_synthesis, label) in enumerate(iterator):\n",
    "            conditional_synthesis, label = conditional_synthesis.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch_size, seq_len = label.shape\n",
    "            \n",
    "            # 这里有问题，应该是输入去掉最后一个token，输出去掉第一个token\n",
    "            # forward pass\n",
    "            output, _ = model(conditional_synthesis, label[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            label = label[:, 1:].contiguous().view(-1)\n",
    "            # # forward pass\n",
    "            # output, _ = model(conditional_synthesis, label)\n",
    "            # output_dim = output.shape[-1] # vocab size\n",
    "            # # ignore the last token and reshape the output\n",
    "            # output = output[:, :-1, :].contiguous().view(-1, output_dim) # (batch_size * seq_len, vocab_size)\n",
    "            # # ignore the first token and reshape the label\n",
    "            # label = label[:, 1:].contiguous().view(-1) # (batch_size * seq_len)\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            # print information\n",
    "            if i % 100 == 0:\n",
    "                print(f'Batch: {i}, Loss: {loss.item()}')\n",
    "        \n",
    "        # calculate the average loss\n",
    "        train_loss_list.append(epoch_loss / len(iterator))\n",
    "        test_loss = test(model, test_loader, criterion, device)\n",
    "        test_loss_list.append(test_loss)\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Train Loss: {epoch_loss / len(iterator)}, Test Loss: {test_loss}')\n",
    "    return train_loss_list, test_loss_list\n",
    "\n",
    "def test(model, iterator, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    generated_sequences = []\n",
    "    with torch.no_grad():\n",
    "        for i, (conditional_synthesis, label) in enumerate(iterator):\n",
    "            conditional_synthesis, label = conditional_synthesis.to(device), label.to(device)\n",
    "            batch_size = conditional_synthesis.shape[0]\n",
    "            # set the initial hidden state\n",
    "            hidden = None\n",
    "            # set the initial input (batch_size, 1)\n",
    "            generated_sequence = label[:, :1] # (batch_size, 1)\n",
    "            batch_loss = 0\n",
    "            \n",
    "            # auto-regressive\n",
    "            for t in range(label.shape[1]):\n",
    "                # forward pass\n",
    "                current_token = generated_sequence[:, -1].unsqueeze(1) # (batch_size, 1)\n",
    "                output, hidden = model(conditional_synthesis, current_token, hidden) # (batch_size, 1, vocab_size)\n",
    "                \n",
    "                # sample for the next input\n",
    "                next_token = sample_from_logits(output.squeeze(1)) # (batch_size,)\n",
    "                generated_sequence = torch.cat([generated_sequence, next_token.unsqueeze(1)], dim=1) # (batch_size, t+2)\n",
    "                \n",
    "                # calculate the loss\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output.view(-1, output_dim) # (batch_size, vocab_size)\n",
    "                label_t = label[:, t]\n",
    "                loss = criterion(output, label_t)\n",
    "                batch_loss += loss.item()\n",
    "            \n",
    "            batch_loss /= label.shape[1]\n",
    "            total_loss += batch_loss\n",
    "            generated_sequences.append(generated_sequence)\n",
    "        \n",
    "        # calculate the average loss\n",
    "        total_loss /= len(iterator)\n",
    "        \n",
    "    # convert the generated sequences to smiles\n",
    "    generated_sequences = torch.cat(generated_sequences, dim=0).cpu().numpy()\n",
    "    generated_sequences = vocab_to_smiles(vocab, generated_sequences)\n",
    "    print(generated_sequences[:10])\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Loss: 3.8012049198150635\n",
      "Batch: 100, Loss: 0.49619123339653015\n",
      "Batch: 200, Loss: 0.36428648233413696\n",
      "['', '+683(Cl)Kc(ICl]C()C(1', '\\\\/7-8\\\\CI<mask>Sc][3C))CCCC', 'N=1](c[+C(CC(C)CCCC)NC()CCCCCcC)<eos>', 'Cl81.', '(7F]CC', ')32[/CCCsC()+1', '3-H1]H2(CC+CN', '', '']\n",
      "Epoch: 0, Train Loss: 0.0, Test Loss: 0.704249394844968\n",
      "Batch: 0, Loss: 0.329321950674057\n",
      "Batch: 100, Loss: 0.31029462814331055\n",
      "Batch: 200, Loss: 0.27776139974594116\n",
      "['(C1NC)CC(CC3CCcN]1(CCC', '3+1CC3(CnCC)))))<eos>', 's(+2C)(CC)CC)CCC', '[++c(c(c1)C)cc=Cc2<eos>', 'KBr', ']](+cCCCCN)C2)CCC)', '/cN[]())nN(((C)CCc))cccC)1(CCC[N++', 'P1](C(C[((()NN)C2NCCC(C[C(1(CCcN2+cc(C)CC)1C)C', '32]cCCCC[3]2CC))3)))C', 'Br1++n12]CCC<eos>']\n",
      "Epoch: 1, Train Loss: 0.0, Test Loss: 0.7398898492897844\n",
      "Batch: 0, Loss: 0.252699077129364\n",
      "Batch: 100, Loss: 0.2279725968837738\n",
      "Batch: 200, Loss: 0.21323490142822266\n",
      "['CC2o[++](C(CC1C)CCCc(Cn)Cc)F', '4c1(CCC)C1c[n2]((c(2(C)C)[(33CC1cc)(c1(C))CC11', 'CC[]N](CCCCC])(C)C(C2', 'Na5Cc<sos>((C)C)21Cc1', '+1CC2C[n++])((CC)CC111C)2', 'cCC[\\\\+C(C1(C(C)CCNC)C))(CC<eos>', '=N1CF(C[N++]2CC(C1C3C)CCC2C)C2<eos>', 'C[CC2N(CCN(C3C)C(C25CC)C1)CC)(', '1[N+]C1)CC(CCCNCCC<eos>', '[+1](C2(CCCCC<eos>n]']\n",
      "Epoch: 2, Train Loss: 0.0, Test Loss: 0.7931637790935548\n",
      "Batch: 0, Loss: 0.21234601736068726\n",
      "Batch: 100, Loss: 0.1919710338115692\n",
      "Batch: 200, Loss: 0.17164380848407745\n",
      "['C[N+](CCCC2CCC)CC3CC', 'C2CC2OC(C[)+N(C)2(C)(C1)(C)C', '(C[N+]1(C(cCC)C<eos>(C)', ')C1C', 'C(Cc1Ncc1cc[n+](3C)', 'C[N+]2C((C)CC)C)(C1', '[N+](1C)CCCCC(C(CNC[N+]1(CC)(CC)((C)C))n1(CNC)C', '1C[N+](C)C(C1C)CCN3CCC1C', 'oO)c2CCC[N+]2(Cn1cCCC)c', 'CC[N+](C)C(CCC)1']\n",
      "Epoch: 3, Train Loss: 0.0, Test Loss: 0.8237589314051178\n",
      "Batch: 0, Loss: 0.16924388706684113\n",
      "Batch: 100, Loss: 0.15840910375118256\n",
      "Batch: 200, Loss: 0.15804627537727356\n",
      "['[N+](C)c(c(C)(C)c1cccc2c2ccc2)CCC1)C', '', '[N+](C)(C)CCC1', 'C1C2C(CC2)(C[N+](CCC)CCC)CC<eos>', '[N+]2(CCC1CCC3)Cc1C', '()[N+](C)(CCCC1)CC1', 'C1Cl[[+]2(C)cc(C)c1CCCCC[N+]1((C)CC)CC', 'c1c1[Nn]1(ccc2CCC14CCCC3CC1[n+](C)(C)ccc()c1C', '', 'C[N+](CC)(CCC2)(C)C']\n",
      "Epoch: 4, Train Loss: 0.0, Test Loss: 0.8700067973740981\n",
      "Batch: 0, Loss: 0.1548096239566803\n",
      "Batch: 100, Loss: 0.1481551080942154\n",
      "Batch: 200, Loss: 0.14548563957214355\n",
      "['[n]1c(ccc)(C1)C2CCC1', 'C1CC(C(C2)C[N+]122CCC2CCC1CC(C)(C)CCCC2C)', '[N+4(C)(CC2)C(CCC1)C', 'c1ccc2[N+](CC(c1C)cn1CC)ccc1', 'C1', 'C11CCCNC([N+](CC(C)C)(C)CK)C', 'C1[N+]+]C4CCCCC2=C1C(C1=C)C', 'N1CCO(CC)CN(CC3CCC[N+](C)(C1)CCCCC2C)C1', 'C1CC223CCCCC(C1)C1C)C', 'c1c(ccc1)CC2C(C)[N+](C)CC1']\n",
      "Epoch: 5, Train Loss: 0.0, Test Loss: 0.9151057018725188\n",
      "Batch: 0, Loss: 0.14568796753883362\n",
      "Batch: 100, Loss: 0.1378539651632309\n",
      "Batch: 200, Loss: 0.1345178782939911\n",
      "['n1n(C(C)C)ccccc12ON(C)C', 'C1C[n+](n(cc2C)CC1)CCCC[n+]1cccn(C)c1)C', 'C1CC2C3[N+](CC(C)CC)(C)1CCCC1', '[N+]3(CC)C(C)CCC1C2(C)C', 'C((C)C)[n+](CCCn[n+]c(C)Cn1CCC)C', '(C[N+](CC)(C1)C)C4', 'C1CC[N+]1(C(C)CCC3)CC2CC(C32CC2)(CC)CC', 'C1CCC2', 'C(CC[N+]1(C)CC3CCCCC1)C', 'C1C2C[N+]2(CC(CC3C)CC1)(C)C1']\n",
      "Epoch: 6, Train Loss: 0.0, Test Loss: 0.9574437499330652\n",
      "Batch: 0, Loss: 0.13262245059013367\n",
      "Batch: 100, Loss: 0.13437604904174805\n",
      "Batch: 200, Loss: 0.12610308825969696\n",
      "['C1C([N+]2(C3CCCC2)CCC2CCC2)c1ccccc1', '[N+]1(CCCC2)(CCCCN(C)C1)C', 'C12C(C)(C3OCC(CN()CC2)C(N(C))C1)C', 'C1N2CCC(C)(C2)C1C[N+](CC2)(C3)CCCC2', 'C2(C)C(C)[N+](CC)(C)CC1', 'C(C)[N+]2(CCCCC3)CC1', 'C1C2c(cccc[n+](c1c(c1)(cccc1)C)C)CCC[N+]22c(C(cc(ccc2)C)(C)CCC)C1', 'C(CN2CCCC1)CCC2', 'n1cc([n+](C)c(C)n1Cc1CC)Ccccn1c', 'c1cc(cc1n1CC[N+]1(CCC)C)C']\n",
      "Epoch: 7, Train Loss: 0.0, Test Loss: 0.9875683899166968\n",
      "Batch: 0, Loss: 0.1264282464981079\n",
      "Batch: 100, Loss: 0.12795795500278473\n",
      "Batch: 200, Loss: 0.1237364411354065\n",
      "['C[++]2(CCCCCCC2)cccccc1', '=(CC)[N+]1(CCCCCC[N+](C)(C)C)C2', 'C1C(N)(C)C(CC[N+](C)(C)Ccc1cccc1)C', 'C[n+]1(Cn(C)cc(C)C)c', 'C1[N+](C)(CCC)C3', 'C([N+]1(CC(C)(C)C)(C)CC3)C', 'n1(C)[n+](CCCCC)c2CCCCCCCCOC', 'N(C)(C)C)C', 'c1c(c([n+](C1CCC2C)cc1)C)Cc1ccccc1', 'c1(C)ccc[n+](Cc1C)Cn1cc[n+](cc1)CCCCC']\n",
      "Epoch: 8, Train Loss: 0.0, Test Loss: 1.0109970200573806\n",
      "Batch: 0, Loss: 0.1179596483707428\n",
      "Batch: 100, Loss: 0.11733116954565048\n",
      "Batch: 200, Loss: 0.11663925647735596\n",
      "['n1cccc(c(c2c1C)C[N+]1(CCC)CCC)(CC1CCCC1', 'c1c(C)C[n+](C[n+](c(c1C)C)CCC)CCCCCCCC[N+](CCCCC)(C)C(C)C', 'C1C(C2C[N+](C)(C)CC1C)(C)(C)C', 'C[N+](C)(C2CCC1Cn2(C)cc3C)C', 'C1(CCC3CCCCCCN1C)C', 'C1CC(CC1)C[N+]1(C)CCC2', '[N+]1(CC2CC4C=CC1C3)CC2CC(C)CC2<eos>', 'C1C#(CC2)C[N+]2(C(CC1)C3)CCCC[N+](C1)(CC)C', 'C[n+]2c1c(C(C)cccc2)C1C', 'Cc1n(C(C)C)[n+](c1)C']\n",
      "Epoch: 9, Train Loss: 0.0, Test Loss: 1.0393232639384586\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_loss_list, test_loss_list = train(n_epoch, model, train_loader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/LSTM_Variant.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training and testing loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "plt.plot(test_loss_list, label='Test Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('./figures/loss.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
