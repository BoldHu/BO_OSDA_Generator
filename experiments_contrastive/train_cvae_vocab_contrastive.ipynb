{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CVAE Model for Conditional Generation Using Pre-setting Vocab and Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hudongcheng/Desktop/bo_osda_generator\n"
     ]
    }
   ],
   "source": [
    "# change working path to the current file\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import custom modules\n",
    "from datasets.data_loader import *\n",
    "from models.cvae import *\n",
    "from models.loss import InfoNCELoss\n",
    "from models.trfm import *\n",
    "from utils.utils import *\n",
    "from utils.plot_figures import *\n",
    "from utils.metrics import *\n",
    "from utils.build_vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "train_ce_loss_history = []\n",
    "test_ce_loss_history = []\n",
    "train_info_loss_history = []\n",
    "test_info_loss_history = []\n",
    "\n",
    "log_dir = './logs/'\n",
    "save_best_weight_path = './checkpoints/'\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "UNK = 1\n",
    "EOS = 2\n",
    "SOS = 3\n",
    "MASK = 4\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocab size is : 45\n",
      "the total num of charset is : 45\n"
     ]
    }
   ],
   "source": [
    "# read the data from the file\n",
    "train_data = pd.read_csv('./data/train_contrastive_dataset.csv')\n",
    "test_data = pd.read_csv('./data/test_contrastive_dataset.csv')\n",
    "\n",
    "vocab = WordVocab.load_vocab('./model_hub/vocab.pkl')\n",
    "print('the vocab size is :', len(vocab))\n",
    "\n",
    "charlen = len(vocab)\n",
    "print('the total num of charset is :', charlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "epoch = 10\n",
    "InfoNCEloss_weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144938/144938 [00:00<00:00, 887094.07it/s] \n",
      "100%|██████████| 144938/144938 [00:00<00:00, 806217.82it/s]\n",
      "100%|██████████| 144938/144938 [00:02<00:00, 50973.11it/s]\n",
      "100%|██████████| 14803/14803 [00:00<00:00, 1686631.59it/s]\n",
      "100%|██████████| 14803/14803 [00:00<00:00, 1064030.06it/s]\n",
      "100%|██████████| 14803/14803 [00:00<00:00, 51331.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# create the dataset and dataloader\n",
    "# train_dataset = Contrastive_Seq2seqDataset(train_data, vocab, MAX_LEN)\n",
    "# test_dataset = Contrastive_Seq2seqDataset(test_data, vocab, MAX_LEN)\n",
    "train_dataset = Contrastive_Seq2seqDataset_random(train_data, vocab, MAX_LEN)\n",
    "test_dataset = Contrastive_Seq2seqDataset_random(test_data, vocab, MAX_LEN)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 1.15M\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have:\n",
    "params = {\n",
    "    'NCHARS': charlen,\n",
    "    'MAX_LEN': MAX_LEN,\n",
    "    'COND_DIM': 24,\n",
    "    'hidden_dim': 256,\n",
    "    'conv_depth': 3,\n",
    "    'conv_dim_depth': 64,\n",
    "    'conv_dim_width': 3,\n",
    "    'conv_d_growth_factor': 2,\n",
    "    'conv_w_growth_factor': 1,\n",
    "    'middle_layer': 2,\n",
    "    'activation': 'tanh',\n",
    "    'batchnorm_conv': True,\n",
    "    'batchnorm_mid': True,\n",
    "    'dropout_rate_mid': 0.2,\n",
    "    'gru_depth': 2,\n",
    "    'recurrent_dim': 256,\n",
    "    # ...\n",
    "}\n",
    "\n",
    "encoder = ConditionalEncoder(\n",
    "    input_channels=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    conv_depth=params['conv_depth'],\n",
    "    conv_dim_depth=params['conv_dim_depth'],\n",
    "    conv_dim_width=params['conv_dim_width'],\n",
    "    conv_d_growth_factor=params['conv_d_growth_factor'],\n",
    "    conv_w_growth_factor=params['conv_w_growth_factor'],\n",
    "    middle_layer=params['middle_layer'],\n",
    "    activation=params['activation'],\n",
    "    batchnorm_conv=params['batchnorm_conv'],\n",
    "    batchnorm_mid=params['batchnorm_mid'],\n",
    "    dropout_rate_mid=params['dropout_rate_mid']\n",
    ").to(device)\n",
    "\n",
    "decoder = ConditionalDecoder(\n",
    "    hidden_dim=params['hidden_dim'],\n",
    "    cond_dim=params['COND_DIM'],\n",
    "    n_chars=params['NCHARS'],\n",
    "    max_len=params['MAX_LEN'],\n",
    "    gru_depth=params['gru_depth'],\n",
    "    recurrent_dim=params['recurrent_dim'],\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "model = ConditionalVAE(encoder, decoder).to(device)\n",
    "\n",
    "# load model\n",
    "trfm = TrfmSeq2seq(charlen, 256, charlen, 4).to(device)\n",
    "trfm.load_state_dict(torch.load('./model_hub/trfm_new_4_130000.pkl'))\n",
    "trfm.eval()\n",
    "\n",
    "# set trfm gradient to false which won't be updated\n",
    "for param in trfm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# loss\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print('total parameters: %0.2fM' % (total / 1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(model, trfm, dataloader, loss_func, optim, device, kl_weight=0.001, pad_idx=0, weight=0.1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: your Conditional VAE\n",
    "        trfm: pretrained transformer model for contrastive learning\n",
    "        dataloader: yields (zeo, syn, tgt) each step\n",
    "        loss_func: typically nn.CrossEntropyLoss(ignore_index=pad_idx) or similar\n",
    "        optim: torch optimizer\n",
    "        device: 'cuda' or 'cpu'\n",
    "        kl_weight: scaling factor for the KL loss term\n",
    "        pad_idx: optional index for <pad>, used in ignoring pad in cross-entropy\n",
    "        weight: weight for the InfoNCE loss term\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_loss_crossentropy = 0\n",
    "    total_loss_infonce = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "\n",
    "    for i, (zeo, syn, tgt, positive_smiles, negative_smiles) in enumerate(tqdm(dataloader)):\n",
    "        # Move data to device\n",
    "        zeo = zeo.to(device)\n",
    "        syn = syn.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        positive_smiles = positive_smiles.to(device)\n",
    "        negative_smiles = negative_smiles.to(device)\n",
    "\n",
    "        # Concatenate to form the full condition\n",
    "        # shape: (batch_size, cond_dim1 + cond_dim2)\n",
    "        condition = torch.cat([zeo, syn], dim=-1)\n",
    "        # tgt: shape (B, seq_len, n_chars) if one-hot approach\n",
    "        tgt_input = tgt[:, :-1].contiguous() # input to the decoder\n",
    "        tgt_target = tgt[:, 1:].contiguous() # target output from the decoder\n",
    "        # convert tgt_input to one -hot code\n",
    "        tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "\n",
    "        # ==========================\n",
    "        # 1) Forward pass\n",
    "        # ==========================.\n",
    "        optim.zero_grad()\n",
    "        logits, z_mean, z_log_var = model(\n",
    "            x_smi=tgt_input,         # SMILES input\n",
    "            x_cond=condition,  # condition\n",
    "            teacher_force_inputs=tgt_input\n",
    "        )\n",
    "\n",
    "        # ==========================\n",
    "        # 2) Compute reconstruction loss\n",
    "        # ==========================\n",
    "        # logits: shape (B, seq_len, n_chars)\n",
    "        logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "        target_ids = tgt_target.view(-1)  # shape (B * seq_len)\n",
    "        recon_loss = loss_func(logits_reshaped, target_ids)\n",
    "        \n",
    "\n",
    "        # ==========================\n",
    "        # 3) Compute KL divergence\n",
    "        # ==========================\n",
    "        # KL = -0.5 * sum(1 + log_var - mean^2 - exp(log_var)) \n",
    "        # We'll average by batch size\n",
    "        kl_loss = -0.5 * torch.sum(\n",
    "            1 + z_log_var - z_mean.pow(2) - z_log_var.exp()\n",
    "        )\n",
    "        kl_loss = kl_loss / tgt.size(0)\n",
    "        \n",
    "        # ==========================\n",
    "        # 4) Compute InfoNCE loss\n",
    "        # ==========================\n",
    "        samples = F.gumbel_softmax(logits, tau=1.0, hard=True)\n",
    "        samples_indices = torch.argmax(samples, dim=-1) # shape (B, seq_len)\n",
    "        # add the start token to the samples\n",
    "        stared_token = torch.ones(samples_indices.size(0), 1, dtype=torch.long).fill_(SOS).to(device)\n",
    "        samples_indices = torch.cat([stared_token, samples_indices], dim=-1)\n",
    "        \n",
    "        # Compute InfoNCE Loss\n",
    "        loss_infonce = InfoNCELoss(samples_indices, positive_smiles, negative_smiles, trfm, temperature=0.07)\n",
    "\n",
    "        # ==========================\n",
    "        # 5) Total loss\n",
    "        # ==========================\n",
    "        loss = recon_loss + kl_weight * kl_loss + weight * loss_infonce\n",
    "\n",
    "        # ==========================\n",
    "        # 6) Backprop & update\n",
    "        # ==========================\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # ==========================\n",
    "        # 7) Compute accuracy (optional)\n",
    "        # ==========================\n",
    "        preds = torch.argmax(logits, dim=-1)  # shape (B, seq_len)\n",
    "        num_correct = (preds == tgt_target) & (tgt_target != pad_idx)\n",
    "        num_words = (tgt_target != pad_idx).sum().item()\n",
    "\n",
    "        # ==========================\n",
    "        # 8) Track stats\n",
    "        # ==========================\n",
    "        total_loss += loss.item()\n",
    "        total_loss_crossentropy += recon_loss.item()\n",
    "        total_loss_infonce += loss_infonce.item()\n",
    "        total_acc += num_correct.sum().item()\n",
    "        total_num += num_words\n",
    "    \n",
    "    return total_loss / len(dataloader), total_loss_crossentropy / len(dataloader), total_loss_infonce / len(dataloader), total_acc / total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate function\n",
    "def evaluate(model, trfm, dataloader, loss_func, device, pad_idx=0, weight=0.1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: your Conditional VAE\n",
    "        trfm: pretrained transformer model for contrastive learning\n",
    "        dataloader: yields (zeo, syn, tgt) each step\n",
    "        loss_func: typically nn.CrossEntropyLoss(ignore_index=pad_idx) or similar\n",
    "        device: 'cuda' or 'cpu'\n",
    "        pad_idx: optional index for <pad>, used in ignoring pad in cross-entropy\n",
    "        weight: weight for the InfoNCE loss term\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_crossentropy = 0\n",
    "    total_loss_infonce = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation during testing\n",
    "        for i, (zeo, syn, tgt) in enumerate(tqdm(dataloader)):\n",
    "            # Move data to device\n",
    "            zeo = zeo.to(device)\n",
    "            syn = syn.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            positive_smiles = positive_smiles.to(device)\n",
    "            negative_smiles = negative_smiles.to(device)\n",
    "\n",
    "            # Concatenate to form the full condition\n",
    "            condition = torch.cat([zeo, syn], dim=-1)\n",
    "            \n",
    "            # One-hot encode the target labels\n",
    "            # tgt: shape (B, seq_len, n_chars) if one-hot approach\n",
    "            tgt_input = tgt[:, :-1].contiguous() # input to the decoder\n",
    "            tgt_target = tgt[:, 1:].contiguous() # target output from the decoder\n",
    "            # convert tgt_input to one -hot code\n",
    "            tgt_input = F.one_hot(tgt_input, num_classes=charlen).float()\n",
    "\n",
    "            # ==========================\n",
    "            # 1) Forward pass\n",
    "            # ==========================\n",
    "            # We use teacher forcing during testing too\n",
    "            logits, z_mean, z_log_var = model(\n",
    "                x_smi=tgt_input,         # SMILES input\n",
    "                x_cond=condition,        # condition\n",
    "                teacher_force_inputs=tgt_input  # Use teacher forcing during inference\n",
    "            )\n",
    "            # logits: shape (B, seq_len, NCHARS) - Output predictions\n",
    "\n",
    "            # ==========================\n",
    "            # 2) Compute reconstruction loss\n",
    "            # ==========================\n",
    "            logits_reshaped = logits.view(-1, logits.size(-1))\n",
    "            target_ids = tgt_target.view(-1)\n",
    "            recon_loss = loss_func(logits_reshaped, target_ids)\n",
    "            \n",
    "        # ==========================\n",
    "        # 3) Compute KL divergence\n",
    "        # ==========================\n",
    "        # KL = -0.5 * sum(1 + log_var - mean^2 - exp(log_var)) \n",
    "        # We'll average by batch size\n",
    "        kl_loss = -0.5 * torch.sum(\n",
    "            1 + z_log_var - z_mean.pow(2) - z_log_var.exp()\n",
    "        )\n",
    "        kl_loss = kl_loss / tgt.size(0)\n",
    "        \n",
    "        # ==========================\n",
    "        # 4) Compute InfoNCE loss\n",
    "        # ==========================\n",
    "        samples = F.gumbel_softmax(logits, tau=1.0, hard=True)\n",
    "        samples_indices = torch.argmax(samples, dim=-1) # shape (B, seq_len)\n",
    "        # add the start token to the samples\n",
    "        stared_token = torch.ones(samples_indices.size(0), 1, dtype=torch.long).fill_(SOS).to(device)\n",
    "        samples_indices = torch.cat([stared_token, samples_indices], dim=-1)\n",
    "        \n",
    "        # Compute InfoNCE Loss\n",
    "        loss_infonce = InfoNCELoss(samples_indices, positive_smiles, negative_smiles, trfm, temperature=0.07)\n",
    "\n",
    "        # ==========================\n",
    "        # 5) Total loss\n",
    "        # ==========================\n",
    "        kl_weight = 0.1\n",
    "        loss = recon_loss + kl_weight * kl_loss + weight * loss_infonce\n",
    "\n",
    "        # ==========================\n",
    "        # 6) Compute accuracy (optional)\n",
    "        # ==========================\n",
    "        preds = torch.argmax(logits, dim=-1)  # shape (B, seq_len)\n",
    "        num_correct = (preds == tgt_target) & (tgt_target != pad_idx)\n",
    "        num_words = (tgt_target != pad_idx).sum().item()\n",
    "\n",
    "        # ==========================\n",
    "        # 7) Track stats\n",
    "        # ==========================\n",
    "        total_loss += loss.item()\n",
    "        total_loss_crossentropy += recon_loss.item()\n",
    "        total_loss_infonce += loss_infonce.item()\n",
    "        total_acc += num_correct.sum().item()\n",
    "        total_num += num_words\n",
    "    \n",
    "    return total_loss / len(dataloader), total_loss_crossentropy / len(dataloader), total_loss_infonce / len(dataloader), total_acc / total_num\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2265 [00:00<?, ?it/s]/home/hudongcheng/miniconda3/envs/zeosyn/lib/python3.7/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 18%|█▊        | 403/2265 [03:21<15:28,  2.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_924779/1060603609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_924779/2640532794.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trfm, dataloader, loss_func, optim, device, kl_weight, pad_idx, weight)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Compute InfoNCE Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mloss_infonce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfoNCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# ==========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/bo_osda_generator/models/loss.py\u001b[0m in \u001b[0;36mInfoNCELoss\u001b[0;34m(sm, sm_positive, sm_negative, trfm, temperature)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# calculate cosine similarity between anchor and positive samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# anchors: (batch_size, embed_dim) -> (batch_size * P, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0manchors_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size * P, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0msim_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m  \u001b[0;31m# (batch_size * P)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for i in range(epoch):\n",
    "    train_loss, train_acc, train_ce, train_info = train(model, trfm, train_dataloader, loss_func, optim, device)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_ce_loss_history.append(train_ce)\n",
    "    train_info_loss_history.append(train_info)\n",
    "    print('epoch: %d, train loss: %.4f, train acc: %.4f, train crossentropy loss: %.4f, train infonce loss: %.4f' % (i, train_loss, train_acc, train_ce, train_info))\n",
    "    test_loss, test_acc, test_ce, test_info = evaluate(model, trfm, test_dataloader, loss_func, device)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_acc_history.append(test_acc)\n",
    "    test_ce_loss_history.append(test_ce)\n",
    "    test_info_loss_history.append(test_info)\n",
    "    print('epoch: %d test loss: %.4f, test acc: %.4f, test crossentropy loss: %.4f, test infonce loss: %.4f' % (i, test_loss, test_acc, test_ce, test_info))\n",
    "    if i == 0:\n",
    "        best_acc = test_acc\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_best_weight_path + 'best_cvae_contrastive_model.pth')\n",
    "    torch.save(model.state_dict(), save_best_weight_path + 'last_cvae_contrastive_model.pth')\n",
    "    \n",
    "    # save every epoch to ./checkpoints/ddc\n",
    "    torch.save(model.state_dict(), save_best_weight_path + '/cvae/cvae_contrastive_model_epoch_%d.pth' % i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cvae(model, condition, tgt_input, vocab, device='cuda', max_len=MAX_LEN, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates SMILES strings from a trained CVAE model, given an already-merged synthesis condition.\n",
    "\n",
    "    Args:\n",
    "        model:       The trained ConditionalVAE model (must implement model.generate).\n",
    "        condition:   (B, cond_dim) - the already-merged condition vector (e.g., torch.cat([zeo, syn], dim=-1)).\n",
    "        tgt_input:   (B, seq_len) - the input SMILES sequence (e.g., the '<sos>' token).\n",
    "        vocab:       The vocabulary object (must implement vocab.idx2char).\n",
    "        device:      'cuda' or 'cpu'.\n",
    "        max_len:     Maximum length of generated SMILES.\n",
    "\n",
    "    Returns:\n",
    "        smiles_list: A list of generated SMILES strings (length = batch size).\n",
    "                     Each string excludes '<sos>', ignores '<pad>', and is cut after '<eos>'.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    smiles_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Move condition to device\n",
    "        condition = condition.to(device)\n",
    "        \n",
    "        # Generate SMILES strings\n",
    "        # Assuming the model has a generate function that takes condition as input\n",
    "        # generated = model.generate(condition, max_len=max_len, device=device, teacher_force_inputs=tgt_input)  # shape: (B, seq_len)\n",
    "        logits, z_mean, z_log = model(\n",
    "            x_smi=tgt_input,         # SMILES input\n",
    "            x_cond=condition,        # condition\n",
    "            teacher_force_inputs=tgt_input  # Use teacher forcing during inference\n",
    "        )\n",
    "\n",
    "        # sample from the logits using multinomial\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        generated = torch.multinomial(probs.view(-1, probs.size(-1)), num_samples=1).view(probs.size(0), probs.size(1))\n",
    "        \n",
    "        \n",
    "        for i in range(generated.size(0)):\n",
    "            # Convert the generated token IDs to SMILES string\n",
    "            smi = []\n",
    "            for idx in generated[i]:\n",
    "                # Convert index to character, skipping padding or other invalid tokens\n",
    "                char = vocab.itos[idx.item()]\n",
    "                if char == '<eos>':  # End of the SMILES string\n",
    "                    break\n",
    "                if char not in ('<sos>', '<pad>'):  # Remove unwanted characters\n",
    "                    smi.append(char)\n",
    "            smiles_list.append(''.join(smi))\n",
    "\n",
    "    return smiles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the smiles for the test dataset\n",
    "generated_smile = []\n",
    "target_smile = []\n",
    "for i, (zeo, syn, tgt, _, _) in enumerate(tqdm(train_dataloader)):\n",
    "    zeo = zeo.to(device)\n",
    "    syn = syn.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    condition_synthesis = torch.cat([zeo, syn], dim=1).to(device)\n",
    "    tgt_input = tgt[:, :-1].contiguous()\n",
    "    # convert the tgt_input to one-hot\n",
    "    tgt_input = F.one_hot(tgt_input, num_classes=params['NCHARS']).float()\n",
    "    generated_smiles = generate_cvae(model=model, condition=condition_synthesis, tgt_input=tgt_input, vocab=vocab, device=device, max_len=MAX_LEN, temperature=1.0)\n",
    "    generated_smile.extend(generated_smiles)\n",
    "    # convert the tgt to smiles\n",
    "    tgt_smiles = []\n",
    "    for seq in tgt:\n",
    "        smiles = ''\n",
    "        for idx in seq:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            elif idx.item() != PAD and idx.item() != SOS:\n",
    "                smiles += vocab.itos[idx.item()]\n",
    "        tgt_smiles.append(smiles)\n",
    "    target_smile.extend(tgt_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics\n",
    "print('Validity rate:', validity_rate(generated_smiles))\n",
    "print('Uniqueness rate:', uniqueness_rate(generated_smiles))\n",
    "print('Novelty rate:', novelty_rate(generated_smiles, target_smile))\n",
    "print('Reconstructability rate:', reconstructability_rate(generated_smiles, target_smile))\n",
    "print('Novelty rate:', novelty_rate(generated_smiles, target_smile))\n",
    "print('IntDiv:', IntDiv(generated_smiles))\n",
    "# print('KL-divergence:', KL_divergence(target_smile), generated_smile))\n",
    "print('FCD score:', FCD_score(target_smile, generated_smile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and acc\n",
    "plot_loss(train_loss_history, test_loss_history, 'cvae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the history to the csv file in log folder\n",
    "history = pd.DataFrame({'train_loss': train_loss_history, 'train_acc': train_acc_history, 'test_loss': test_loss_history, 'test_acc': test_acc_history, 'train_ce_loss': train_ce_loss_history, 'test_ce_loss': test_ce_loss_history, 'train_info_loss': train_info_loss_history, 'test_info_loss': test_info_loss_history})\n",
    "history.to_csv(log_dir + 'ddc_contrastive_history.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeosyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
